2020-11-08 16:59:41 - Starting training job for model Transformer Encoder
2020-11-08 16:59:41 - Decreased the learning rate and changed from adam to adamw optimizer. Also changed the weight initialization
2020-11-08 16:59:52 - Transformer Encoder Hyper Params
2020-11-08 16:59:52 - {
    "input_size": 78,
    "output_size": 11,
    "num_head": 6,
    "hidden_size": 128,
    "num_layers": 5,
    "dropout": 0.1
}
2020-11-08 16:59:52 - Transformer Encoder Job params
2020-11-08 16:59:53 - {
    "qpm_index": false,
    "vel_param_idx": 0,
    "dev_param_idx": 2,
    "articul_param_idx": 3,
    "pedal_param_idx": 4,
    "time_steps": 500,
    "num_key_augmentation": 1,
    "batch_size": 1,
    "num_tempo_param": 1,
    "num_input": 78,
    "num_output": 11,
    "num_prime_param": 11,
    "device_num": 1,
    "is_dev": false,
    "learning_rate": 3e-05,
    "grad_clip": 0.5,
    "model_name": "TRANSFORMER ENCODER ONLY"
}
2020-11-08 16:59:59 - Reading Full Data
2020-11-08 16:59:59 - Loading the training data
2020-11-08 17:00:18 - Reading Full Data
2020-11-08 17:00:18 - Loading the training data
2020-11-08 17:11:59 - number of train performances: 709 number of valid perf: 82
2020-11-08 17:11:59 - training sample example: [-1.962150341422854, -0.06717901528552674, 1.8699356872077189, 0.13782855458600415, 0.5691738323041352, -0.0476638292090852, -0.6179821514476284, -0.7241930870686905, 0.0, 0.0, 0, 0, 0, -0.5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.5, 0, 0, 0, 0, -0.7, 0, 0, 0.3, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.5, 0]
2020-11-08 17:12:07 - STARTING None TRAINING VERSION 0.2 JOB AT 30 EPOCHS FOR  DATA SET
2020-11-08 17:12:08 - Number of model params: 226539
2020-11-08 17:12:08 - TransformerEncoder(
  (pos_encoder): PositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)
        )
        (linear1): Linear(in_features=78, out_features=128, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=128, out_features=78, bias=True)
        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)
        )
        (linear1): Linear(in_features=78, out_features=128, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=128, out_features=78, bias=True)
        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)
        )
        (linear1): Linear(in_features=78, out_features=128, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=128, out_features=78, bias=True)
        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)
        )
        (linear1): Linear(in_features=78, out_features=128, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=128, out_features=78, bias=True)
        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)
        )
        (linear1): Linear(in_features=78, out_features=128, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=128, out_features=78, bias=True)
        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (decoder): Linear(in_features=78, out_features=11, bias=True)
)
2020-11-08 17:12:08 - Training Epoch 1
2020-11-08 17:12:08 - 
2020-11-08 17:25:16 - Training Loss
2020-11-08 17:25:16 - Total Loss: 0.9497611191075006
2020-11-08 17:25:16 - 	tempo: 0.5283 vel: 0.7104 dev: 1.687 articul: 0.9769 pedal: 0.935 trill: 0.0 kld: nan 
2020-11-08 17:25:16 - 
2020-11-08 17:25:25 - Validation loss
2020-11-08 17:25:25 - Total Loss: 0.7906533459172602
2020-11-08 17:25:25 - 	tempo: 0.4288 vel: 0.5895 dev: 0.764 articul: 1.017 pedal: 0.8425 trill: 0.0 kld: nan 
2020-11-08 17:25:25 - 
2020-11-08 17:25:25 - 
2020-11-08 17:25:25 - Training Epoch 2
2020-11-08 17:25:25 - 
2020-11-08 17:38:46 - Training Loss
2020-11-08 17:38:46 - Total Loss: 0.8704299450526393
2020-11-08 17:38:46 - 	tempo: 0.3729 vel: 0.584 dev: 1.68 articul: 0.9072 pedal: 0.8615 trill: 0.0 kld: nan 
2020-11-08 17:38:46 - 
2020-11-08 17:38:56 - Validation loss
2020-11-08 17:38:56 - Total Loss: 0.7659602752790369
2020-11-08 17:38:56 - 	tempo: 0.4358 vel: 0.5936 dev: 0.7738 articul: 0.9762 pedal: 0.8066 trill: 0.0 kld: nan 
2020-11-08 17:38:56 - 
2020-11-08 17:38:56 - 
2020-11-08 17:38:56 - Training Epoch 3
2020-11-08 17:38:56 - 
2020-11-08 17:52:03 - Training Loss
2020-11-08 17:52:03 - Total Loss: 0.8532671944593198
2020-11-08 17:52:03 - 	tempo: 0.3357 vel: 0.5494 dev: 1.735 articul: 0.8719 pedal: 0.842 trill: 0.0 kld: nan 
2020-11-08 17:52:03 - 
2020-11-08 17:52:13 - Validation loss
2020-11-08 17:52:13 - Total Loss: 0.7602073916803218
2020-11-08 17:52:13 - 	tempo: 0.4339 vel: 0.5833 dev: 0.7593 articul: 0.9689 pedal: 0.8024 trill: 0.0 kld: nan 
2020-11-08 17:52:13 - 
2020-11-08 17:52:13 - 
2020-11-08 17:52:13 - Training Epoch 4
2020-11-08 17:52:13 - 
2020-11-08 18:05:06 - Training Loss
2020-11-08 18:05:06 - Total Loss: 0.87672738546354
2020-11-08 18:05:06 - 	tempo: 0.311 vel: 0.5237 dev: 2.16 articul: 0.8541 pedal: 0.8279 trill: 0.0 kld: nan 
2020-11-08 18:05:06 - 
2020-11-08 18:05:16 - Validation loss
2020-11-08 18:05:16 - Total Loss: 0.7519800280769394
2020-11-08 18:05:16 - 	tempo: 0.3924 vel: 0.5547 dev: 0.759 articul: 0.9601 pedal: 0.8008 trill: 0.0 kld: nan 
2020-11-08 18:05:16 - 
2020-11-08 18:05:16 - 
2020-11-08 18:05:16 - Training Epoch 5
2020-11-08 18:05:16 - 
2020-11-08 18:18:58 - Training Loss
2020-11-08 18:18:58 - Total Loss: 0.8573191851301214
2020-11-08 18:18:58 - 	tempo: 0.2899 vel: 0.5043 dev: 2.056 articul: 0.8392 pedal: 0.8202 trill: 0.0 kld: nan 
2020-11-08 18:18:58 - 
2020-11-08 18:19:08 - Validation loss
2020-11-08 18:19:08 - Total Loss: 0.7494333656934592
2020-11-08 18:19:08 - 	tempo: 0.3759 vel: 0.5312 dev: 0.7577 articul: 0.95 pedal: 0.8041 trill: 0.0 kld: nan 
2020-11-08 18:19:08 - 
2020-11-08 18:19:08 - 
2020-11-08 18:19:09 - Training Epoch 6
2020-11-08 18:19:09 - 
2020-11-08 18:32:28 - Training Loss
2020-11-08 18:32:28 - Total Loss: 0.8283289001341965
2020-11-08 18:32:28 - 	tempo: 0.2736 vel: 0.4905 dev: 1.819 articul: 0.828 pedal: 0.8144 trill: 0.0 kld: nan 
2020-11-08 18:32:28 - 
2020-11-08 18:32:37 - Validation loss
2020-11-08 18:32:37 - Total Loss: 0.7449358924969065
2020-11-08 18:32:37 - 	tempo: 0.3599 vel: 0.5165 dev: 0.7723 articul: 0.9411 pedal: 0.8006 trill: 0.0 kld: nan 
2020-11-08 18:32:37 - 
2020-11-08 18:32:37 - 
2020-11-08 18:32:37 - Training Epoch 7
2020-11-08 18:32:37 - 
2020-11-08 18:46:02 - Training Loss
2020-11-08 18:46:02 - Total Loss: 0.790606796486449
2020-11-08 18:46:02 - 	tempo: 0.2616 vel: 0.4787 dev: 1.483 articul: 0.8166 pedal: 0.8081 trill: 0.0 kld: nan 
2020-11-08 18:46:02 - 
2020-11-08 18:46:12 - Validation loss
2020-11-08 18:46:12 - Total Loss: 0.7422014258776334
2020-11-08 18:46:12 - 	tempo: 0.3332 vel: 0.4979 dev: 0.7569 articul: 0.9195 pedal: 0.8081 trill: 0.0 kld: nan 
2020-11-08 18:46:12 - 
2020-11-08 18:46:12 - 
2020-11-08 18:46:12 - Training Epoch 8
2020-11-08 18:46:12 - 
2020-11-08 18:59:30 - Training Loss
2020-11-08 18:59:30 - Total Loss: 0.8075749805129252
2020-11-08 18:59:30 - 	tempo: 0.2501 vel: 0.4681 dev: 1.732 articul: 0.8075 pedal: 0.8036 trill: 0.0 kld: nan 
2020-11-08 18:59:30 - 
2020-11-08 18:59:39 - Validation loss
2020-11-08 18:59:39 - Total Loss: 0.7474731943659161
2020-11-08 18:59:39 - 	tempo: 0.3435 vel: 0.5003 dev: 0.7618 articul: 0.9139 pedal: 0.8147 trill: 0.0 kld: nan 
2020-11-08 18:59:39 - 
2020-11-08 18:59:39 - 
2020-11-08 18:59:40 - Training Epoch 9
2020-11-08 18:59:40 - 
2020-11-08 19:13:04 - Training Loss
2020-11-08 19:13:04 - Total Loss: 0.8411055805677761
2020-11-08 19:13:04 - 	tempo: 0.2428 vel: 0.4605 dev: 2.159 articul: 0.8005 pedal: 0.7984 trill: 0.0 kld: nan 
2020-11-08 19:13:04 - 
2020-11-08 19:13:12 - Validation loss
2020-11-08 19:13:12 - Total Loss: 0.7327328383404276
2020-11-08 19:13:12 - 	tempo: 0.3337 vel: 0.491 dev: 0.7597 articul: 0.9055 pedal: 0.7957 trill: 0.0 kld: nan 
2020-11-08 19:13:12 - 
2020-11-08 19:13:12 - 
2020-11-08 19:13:12 - Training Epoch 10
2020-11-08 19:13:12 - 
2020-11-08 19:26:21 - Training Loss
2020-11-08 19:26:21 - Total Loss: 0.8148643256618224
2020-11-08 19:26:21 - 	tempo: 0.2342 vel: 0.4527 dev: 1.919 articul: 0.7917 pedal: 0.7952 trill: 0.0 kld: nan 
2020-11-08 19:26:21 - 
2020-11-08 19:26:30 - Validation loss
2020-11-08 19:26:30 - Total Loss: 0.7455156413131747
2020-11-08 19:26:30 - 	tempo: 0.3512 vel: 0.5034 dev: 0.7555 articul: 0.8968 pedal: 0.8134 trill: 0.0 kld: nan 
2020-11-08 19:26:30 - 
2020-11-08 19:26:30 - 
2020-11-08 19:26:30 - Training Epoch 11
2020-11-08 19:26:30 - 
2020-11-08 19:40:01 - Training Loss
2020-11-08 19:40:01 - Total Loss: 0.7915836719526508
2020-11-08 19:40:01 - 	tempo: 0.2272 vel: 0.4467 dev: 1.721 articul: 0.7854 pedal: 0.7896 trill: 0.0 kld: nan 
2020-11-08 19:40:01 - 
2020-11-08 19:40:11 - Validation loss
2020-11-08 19:40:11 - Total Loss: 0.7490337562468863
2020-11-08 19:40:11 - 	tempo: 0.3458 vel: 0.5008 dev: 0.7567 articul: 0.8843 pedal: 0.8217 trill: 0.0 kld: nan 
2020-11-08 19:40:11 - 
2020-11-08 19:40:11 - 
2020-11-08 19:40:12 - Training Epoch 12
2020-11-08 19:40:12 - 
2020-11-08 19:54:02 - Training Loss
2020-11-08 19:54:02 - Total Loss: 0.817770407915808
2020-11-08 19:54:02 - 	tempo: 0.2226 vel: 0.4413 dev: 2.045 articul: 0.7773 pedal: 0.787 trill: 0.0 kld: nan 
2020-11-08 19:54:02 - 
2020-11-08 19:54:20 - Validation loss
2020-11-08 19:54:21 - Total Loss: 0.747106595154665
2020-11-08 19:54:21 - 	tempo: 0.3351 vel: 0.493 dev: 0.7566 articul: 0.8782 pedal: 0.8222 trill: 0.0 kld: nan 
2020-11-08 19:54:21 - 
2020-11-08 19:54:21 - 
2020-11-08 19:54:21 - Training Epoch 13
2020-11-08 19:54:21 - 
2020-11-08 20:07:31 - Training Loss
2020-11-08 20:07:31 - Total Loss: 0.7956271829691312
2020-11-08 20:07:31 - 	tempo: 0.2162 vel: 0.4362 dev: 1.851 articul: 0.7717 pedal: 0.7823 trill: 0.0 kld: nan 
2020-11-08 20:07:31 - 
2020-11-08 20:07:40 - Validation loss
2020-11-08 20:07:40 - Total Loss: 0.7532621017831943
2020-11-08 20:07:40 - 	tempo: 0.3725 vel: 0.5149 dev: 0.7558 articul: 0.8618 pedal: 0.8258 trill: 0.0 kld: nan 
2020-11-08 20:07:40 - 
2020-11-08 20:07:40 - 
2020-11-08 20:07:41 - Training Epoch 14
2020-11-08 20:07:41 - 
2020-11-08 20:21:18 - Training Loss
2020-11-08 20:21:18 - Total Loss: 0.7856419324113416
2020-11-08 20:21:18 - 	tempo: 0.2107 vel: 0.4313 dev: 1.788 articul: 0.7649 pedal: 0.7781 trill: 0.0 kld: nan 
2020-11-08 20:21:18 - 
2020-11-08 20:21:27 - Validation loss
2020-11-08 20:21:27 - Total Loss: 0.7436235080128664
2020-11-08 20:21:27 - 	tempo: 0.3486 vel: 0.4965 dev: 0.7502 articul: 0.8629 pedal: 0.8174 trill: 0.0 kld: nan 
2020-11-08 20:21:27 - 
2020-11-08 20:21:27 - 
2020-11-08 20:21:27 - Training Epoch 15
2020-11-08 20:21:27 - 
2020-11-08 20:34:58 - Training Loss
2020-11-08 20:34:58 - Total Loss: 0.802201991252563
2020-11-08 20:34:58 - 	tempo: 0.2073 vel: 0.4279 dev: 2.004 articul: 0.7592 pedal: 0.7751 trill: 0.0 kld: nan 
2020-11-08 20:34:58 - 
2020-11-08 20:35:09 - Validation loss
2020-11-08 20:35:09 - Total Loss: 0.7371056932542059
2020-11-08 20:35:09 - 	tempo: 0.3458 vel: 0.4956 dev: 0.7622 articul: 0.8541 pedal: 0.8072 trill: 0.0 kld: nan 
2020-11-08 20:35:09 - 
2020-11-08 20:35:09 - 
2020-11-08 20:35:09 - Training Epoch 16
2020-11-08 20:35:09 - 
2020-11-08 20:48:35 - Training Loss
2020-11-08 20:48:35 - Total Loss: 0.8363477480334927
2020-11-08 20:48:35 - 	tempo: 0.2034 vel: 0.4241 dev: 2.4 articul: 0.7565 pedal: 0.7736 trill: 0.0 kld: nan 
2020-11-08 20:48:35 - 
2020-11-08 20:48:44 - Validation loss
2020-11-08 20:48:44 - Total Loss: 0.7358577018523258
2020-11-08 20:48:44 - 	tempo: 0.3263 vel: 0.4884 dev: 0.7539 articul: 0.8456 pedal: 0.8115 trill: 0.0 kld: nan 
2020-11-08 20:48:44 - 
2020-11-08 20:48:44 - 
2020-11-08 20:48:44 - Training Epoch 17
2020-11-08 20:48:44 - 
2020-11-08 21:02:30 - Training Loss
2020-11-08 21:02:30 - Total Loss: 0.7913840976232074
2020-11-08 21:02:30 - 	tempo: 0.1997 vel: 0.4211 dev: 1.941 articul: 0.751 pedal: 0.7704 trill: 0.0 kld: nan 
2020-11-08 21:02:30 - 
2020-11-08 21:02:40 - Validation loss
2020-11-08 21:02:40 - Total Loss: 0.7311793703240218
2020-11-08 21:02:40 - 	tempo: 0.3392 vel: 0.4903 dev: 0.7524 articul: 0.8405 pedal: 0.8029 trill: 0.0 kld: nan 
2020-11-08 21:02:40 - 
2020-11-08 21:02:40 - 
2020-11-08 21:02:40 - Training Epoch 18
2020-11-08 21:02:40 - 
2020-11-08 21:15:59 - Training Loss
2020-11-08 21:15:59 - Total Loss: 0.8004803123453568
2020-11-08 21:15:59 - 	tempo: 0.1978 vel: 0.4182 dev: 2.051 articul: 0.747 pedal: 0.7702 trill: 0.0 kld: nan 
2020-11-08 21:15:59 - 
2020-11-08 21:16:09 - Validation loss
2020-11-08 21:16:09 - Total Loss: 0.7416403698504885
2020-11-08 21:16:09 - 	tempo: 0.3411 vel: 0.4922 dev: 0.7481 articul: 0.8348 pedal: 0.8203 trill: 0.0 kld: nan 
2020-11-08 21:16:09 - 
2020-11-08 21:16:09 - 
2020-11-08 21:16:10 - Training Epoch 19
2020-11-08 21:16:10 - 
2020-11-08 21:30:07 - Training Loss
2020-11-08 21:30:07 - Total Loss: 0.832168359434217
2020-11-08 21:30:07 - 	tempo: 0.1952 vel: 0.4166 dev: 2.434 articul: 0.745 pedal: 0.7662 trill: 0.0 kld: nan 
2020-11-08 21:30:07 - 
2020-11-08 21:30:25 - Validation loss
2020-11-08 21:30:25 - Total Loss: 0.738689677448215
2020-11-08 21:30:25 - 	tempo: 0.3347 vel: 0.4938 dev: 0.7537 articul: 0.8363 pedal: 0.8153 trill: 0.0 kld: nan 
2020-11-08 21:30:25 - 
2020-11-08 21:30:25 - 
2020-11-08 21:30:26 - Training Epoch 20
2020-11-08 21:30:26 - 
2020-11-08 21:43:59 - Training Loss
2020-11-08 21:43:59 - Total Loss: 0.790767623764198
2020-11-08 21:43:59 - 	tempo: 0.1909 vel: 0.4118 dev: 1.999 articul: 0.7397 pedal: 0.7653 trill: 0.0 kld: nan 
2020-11-08 21:43:59 - 
2020-11-08 21:44:09 - Validation loss
2020-11-08 21:44:09 - Total Loss: 0.7479307154559681
2020-11-08 21:44:09 - 	tempo: 0.3442 vel: 0.4964 dev: 0.749 articul: 0.8346 pedal: 0.829 trill: 0.0 kld: nan 
2020-11-08 21:44:09 - 
2020-11-08 21:44:09 - 
2020-11-08 21:44:10 - Training Epoch 21
2020-11-08 21:44:10 - 
2020-11-08 21:57:35 - Training Loss
2020-11-08 21:57:35 - Total Loss: 0.7642844689510986
2020-11-08 21:57:35 - 	tempo: 0.1905 vel: 0.4109 dev: 1.731 articul: 0.7383 pedal: 0.7623 trill: 0.0 kld: nan 
2020-11-08 21:57:35 - 
2020-11-08 21:57:45 - Validation loss
2020-11-08 21:57:45 - Total Loss: 0.7381678384613909
2020-11-08 21:57:45 - 	tempo: 0.3173 vel: 0.4797 dev: 0.7496 articul: 0.8344 pedal: 0.8199 trill: 0.0 kld: nan 
2020-11-08 21:57:45 - 
2020-11-08 21:57:45 - 
2020-11-08 21:57:45 - Training Epoch 22
2020-11-08 21:57:45 - 
2020-11-08 22:11:29 - Training Loss
2020-11-08 22:11:29 - Total Loss: 0.7612929849992438
2020-11-08 22:11:29 - 	tempo: 0.1872 vel: 0.4079 dev: 1.733 articul: 0.7351 pedal: 0.7588 trill: 0.0 kld: nan 
2020-11-08 22:11:29 - 
2020-11-08 22:11:41 - Validation loss
2020-11-08 22:11:41 - Total Loss: 0.7436300780528631
2020-11-08 22:11:41 - 	tempo: 0.3405 vel: 0.5027 dev: 0.7516 articul: 0.834 pedal: 0.8216 trill: 0.0 kld: nan 
2020-11-08 22:11:41 - 
2020-11-08 22:11:41 - 
2020-11-08 22:11:42 - Training Epoch 23
2020-11-08 22:11:42 - 
2020-11-08 22:25:27 - Training Loss
2020-11-08 22:25:27 - Total Loss: 0.7864023456671062
2020-11-08 22:25:27 - 	tempo: 0.1875 vel: 0.407 dev: 2.019 articul: 0.7315 pedal: 0.7578 trill: 0.0 kld: nan 
2020-11-08 22:25:27 - 
2020-11-08 22:25:36 - Validation loss
2020-11-08 22:25:36 - Total Loss: 0.7366575939027039
2020-11-08 22:25:36 - 	tempo: 0.3426 vel: 0.497 dev: 0.7446 articul: 0.8295 pedal: 0.8128 trill: 0.0 kld: nan 
2020-11-08 22:25:36 - 
2020-11-08 22:25:36 - 
2020-11-08 22:25:37 - Training Epoch 24
2020-11-08 22:25:37 - 
2020-11-08 22:39:12 - Training Loss
2020-11-08 22:39:12 - Total Loss: 0.7842034401564929
2020-11-08 22:39:12 - 	tempo: 0.1845 vel: 0.4041 dev: 2.007 articul: 0.7282 pedal: 0.7575 trill: 0.0 kld: nan 
2020-11-08 22:39:12 - 
2020-11-08 22:39:31 - Validation loss
2020-11-08 22:39:31 - Total Loss: 0.7330057625634683
2020-11-08 22:39:31 - 	tempo: 0.3327 vel: 0.4915 dev: 0.7526 articul: 0.8325 pedal: 0.8077 trill: 0.0 kld: nan 
2020-11-08 22:39:31 - 
2020-11-08 22:39:31 - 
2020-11-08 22:39:32 - Training Epoch 25
2020-11-08 22:39:32 - 
2020-11-08 22:53:13 - Training Loss
2020-11-08 22:53:13 - Total Loss: 0.8216885709238901
2020-11-08 22:53:13 - 	tempo: 0.1821 vel: 0.4023 dev: 2.45 articul: 0.7252 pedal: 0.7541 trill: 0.0 kld: nan 
2020-11-08 22:53:13 - 
2020-11-08 22:53:22 - Validation loss
2020-11-08 22:53:22 - Total Loss: 0.7366839270667522
2020-11-08 22:53:22 - 	tempo: 0.3518 vel: 0.501 dev: 0.7538 articul: 0.8328 pedal: 0.8092 trill: 0.0 kld: nan 
2020-11-08 22:53:22 - 
2020-11-08 22:53:22 - 
2020-11-08 22:53:23 - Training Epoch 26
2020-11-08 22:53:23 - 
2020-11-08 23:06:54 - Training Loss
2020-11-08 23:06:54 - Total Loss: 0.7668063323328318
2020-11-08 23:06:54 - 	tempo: 0.1817 vel: 0.4007 dev: 1.853 articul: 0.723 pedal: 0.7538 trill: 0.0 kld: nan 
2020-11-08 23:06:54 - 
2020-11-08 23:07:04 - Validation loss
2020-11-08 23:07:04 - Total Loss: 0.7479389743535219
2020-11-08 23:07:04 - 	tempo: 0.355 vel: 0.5035 dev: 0.7647 articul: 0.8293 pedal: 0.825 trill: 0.0 kld: nan 
2020-11-08 23:07:04 - 
2020-11-08 23:07:04 - 
2020-11-08 23:07:05 - Training Epoch 27
2020-11-08 23:07:05 - 
2020-11-08 23:20:37 - Training Loss
2020-11-08 23:20:37 - Total Loss: 0.8311931119692733
2020-11-08 23:20:37 - 	tempo: 0.1793 vel: 0.3985 dev: 2.581 articul: 0.7207 pedal: 0.7519 trill: 0.0 kld: nan 
2020-11-08 23:20:37 - 
2020-11-08 23:20:49 - Validation loss
2020-11-08 23:20:49 - Total Loss: 0.734206831639575
2020-11-08 23:20:49 - 	tempo: 0.3401 vel: 0.4981 dev: 0.7656 articul: 0.8268 pedal: 0.8065 trill: 0.0 kld: nan 
2020-11-08 23:20:49 - 
2020-11-08 23:20:49 - 
2020-11-08 23:20:49 - Training Epoch 28
2020-11-08 23:20:49 - 
2020-11-08 23:34:27 - Training Loss
2020-11-08 23:34:27 - Total Loss: 0.7828201049142771
2020-11-08 23:34:27 - 	tempo: 0.1776 vel: 0.3967 dev: 2.062 articul: 0.7179 pedal: 0.7509 trill: 0.0 kld: nan 
2020-11-08 23:34:27 - 
2020-11-08 23:34:37 - Validation loss
2020-11-08 23:34:37 - Total Loss: 0.7421316131694268
2020-11-08 23:34:37 - 	tempo: 0.3615 vel: 0.5041 dev: 0.7696 articul: 0.8283 pedal: 0.8143 trill: 0.0 kld: nan 
2020-11-08 23:34:37 - 
2020-11-08 23:34:37 - 
2020-11-08 23:34:38 - Training Epoch 29
2020-11-08 23:34:38 - 
2020-11-08 23:48:17 - Training Loss
2020-11-08 23:48:17 - Total Loss: 0.7610487994025735
2020-11-08 23:48:17 - 	tempo: 0.1769 vel: 0.3955 dev: 1.827 articul: 0.7161 pedal: 0.7509 trill: 0.0 kld: nan 
2020-11-08 23:48:17 - 
2020-11-08 23:48:27 - Validation loss
2020-11-08 23:48:27 - Total Loss: 0.7385369328075442
2020-11-08 23:48:27 - 	tempo: 0.3441 vel: 0.4989 dev: 0.759 articul: 0.8349 pedal: 0.8124 trill: 0.0 kld: nan 
2020-11-08 23:48:27 - 
2020-11-08 23:48:27 - 
2020-11-08 23:48:27 - Training Epoch 30
2020-11-08 23:48:27 - 
2020-11-09 00:02:04 - Training Loss
2020-11-09 00:02:04 - Total Loss: 0.8297695909783644
2020-11-09 00:02:04 - 	tempo: 0.1756 vel: 0.3943 dev: 2.609 articul: 0.713 pedal: 0.7479 trill: 0.0 kld: nan 
2020-11-09 00:02:04 - 
2020-11-09 00:02:14 - Validation loss
2020-11-09 00:02:14 - Total Loss: 0.7367996896602835
2020-11-09 00:02:14 - 	tempo: 0.342 vel: 0.4968 dev: 0.749 articul: 0.8299 pedal: 0.8124 trill: 0.0 kld: nan 
2020-11-09 00:02:14 - 
2020-11-09 00:02:14 - 
2020-11-09 00:02:15 - FINISHED None VERSION 0.2 TRAINING JOB AT 30 EPOCHS FOR  DATA SET
