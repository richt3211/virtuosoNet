{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.experiments.training.training import run_training_experiment\n",
    "from src.models.transformer import TransformerEncoder, TransformerEncoderHyperParams\n",
    "from src.experiments.training.Transformer.TransformerEncoder_training import TransformerEncoderJob, TransformerEncoderJobParams\n",
    "from src.models.model_run_job import ModelJob, ModelJobParams\n",
    "from src.constants import SRC_DIR\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = 1\n",
    "pedal = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerEncoderJobParams(input_size=78, output_size=11, device_num=1, time_steps=500, is_dev=True, device=device(type='cuda', index=1), qpm_index=0, vel_param_idx=1, dev_param_idx=2, articul_param_idx=3, pedal_param_idx=4, num_key_augmentation=1, batch_size=1, epochs=50, num_tempo_param=1, num_prime_param=11, criterion='torch', tempo_loss=True, articul_mask='pedal', tempo_weight=1, vel_weight=1, dev_weight=1, articul_weight=1, pedal_weight=7, learning_rate=3e-05, grad_clip=0.5, model_name='TRANSFORMER ENCODER ONLY')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "is_dev=True\n",
    "hyper_params = TransformerEncoderHyperParams(hidden_size=128, num_layers=6, num_head=6)\n",
    "job_params = TransformerEncoderJobParams(\n",
    "    is_dev=is_dev, \n",
    "    articul_mask=\"pedal\", \n",
    "    articul_weight = other,\n",
    "    dev_weight = other,\n",
    "    pedal_weight = pedal,\n",
    "    vel_weight = other,\n",
    "    tempo_weight=other, \n",
    ")\n",
    "model_file_path = f\"{SRC_DIR}/models/transformer.py\"\n",
    "exp_name=\"Reducing hidden size\"\n",
    "exp_description=\"Making sure we have models that we produce results for\"\n",
    "model_class=TransformerEncoder\n",
    "job_class=TransformerEncoderJob\n",
    "tags=['transformer_encoder']\n",
    "display(job_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"input_size\": 78,\n",
      "    \"output_size\": 11,\n",
      "    \"device_num\": 1,\n",
      "    \"time_steps\": 500,\n",
      "    \"is_dev\": true,\n",
      "    \"device\": \"cuda:1\",\n",
      "    \"num_head\": 6,\n",
      "    \"hidden_size\": 128,\n",
      "    \"num_layers\": 6,\n",
      "    \"dropout\": 0.1,\n",
      "    \"qpm_index\": 0,\n",
      "    \"vel_param_idx\": 1,\n",
      "    \"dev_param_idx\": 2,\n",
      "    \"articul_param_idx\": 3,\n",
      "    \"pedal_param_idx\": 4,\n",
      "    \"num_key_augmentation\": 1,\n",
      "    \"batch_size\": 1,\n",
      "    \"epochs\": 50,\n",
      "    \"num_tempo_param\": 1,\n",
      "    \"num_prime_param\": 11,\n",
      "    \"criterion\": \"torch\",\n",
      "    \"tempo_loss\": true,\n",
      "    \"articul_mask\": \"pedal\",\n",
      "    \"tempo_weight\": 1,\n",
      "    \"vel_weight\": 1,\n",
      "    \"dev_weight\": 1,\n",
      "    \"articul_weight\": 1,\n",
      "    \"pedal_weight\": 7,\n",
      "    \"learning_rate\": 3e-05,\n",
      "    \"grad_clip\": 0.5,\n",
      "    \"model_name\": \"TRANSFORMER ENCODER ONLY\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There is a new version of neptune-client 0.4.130 (installed: 0.4.126).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ai/richt3211/thesis/e/THESIS-179\n",
      "2021-01-11 12:50:42 - Starting experiment\n",
      "2021-01-11 12:50:43 - Reading Dev Data\n",
      "2021-01-11 12:50:48 - STARTING None JOB AT 50 EPOCHS FOR DEV DATA SET\n",
      "2021-01-11 12:50:49 - Number of model params: 271673\n",
      "2021-01-11 12:50:49 - TransformerEncoder(\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=128, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=128, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=128, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=128, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=128, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=128, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=78, out_features=11, bias=True)\n",
      ")\n",
      "2021-01-11 12:50:50 - Training Epoch 1\n",
      "2021-01-11 12:50:58 - Invalid metric value: nan for channel train kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2021-01-11 12:50:58 - train total loss: 0.9583061321576436tempo loss: 0.26606966329428056, vel loss: 0.9896102567513784, dev loss: 0.7356951713562012, articul loss: 1.2058509222666423, pedal loss: 1.0491630152861278, trill loss: 0.0, kld loss: nan, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uusoc/exports/scratch/rtimpson/thesis/virtuosoNet/env/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/uusoc/exports/scratch/rtimpson/thesis/virtuosoNet/env/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-11 12:51:00 - Invalid metric value: nan for channel valid kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2021-01-11 12:51:00 - valid total loss: 1.277360846598943tempo loss: 4.657789866129558, vel loss: 1.1256258487701416, dev loss: 0.8158207361896833, articul loss: 1.126581201950709, pedal loss: 0.9035930534203848, trill loss: 0.0, kld loss: nan, \n",
      "2021-01-11 12:51:00 - Trained model for 1 epochs with validation loss of 1.277360846598943\n",
      "2021-01-11 12:51:09 - saving model at epoch 1 as the best model\n",
      "2021-01-11 12:51:10 - Training Epoch 2\n",
      "2021-01-11 12:51:16 - Invalid metric value: nan for channel train kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2021-01-11 12:51:16 - train total loss: 0.8611932671689367tempo loss: 0.1545824960697736, vel loss: 0.8879457352223334, dev loss: 0.7196280391185315, articul loss: 0.8686511988763685, pedal loss: 0.9774740288009891, trill loss: 0.0, kld loss: nan, \n",
      "2021-01-11 12:51:16 - Invalid metric value: nan for channel valid kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2021-01-11 12:51:16 - valid total loss: 1.2796698212623596tempo loss: 4.936954816182454, vel loss: 1.1669587691624959, dev loss: 0.8312119121352831, articul loss: 0.9742407302061716, pedal loss: 0.8810002009073893, trill loss: 0.0, kld loss: nan, \n",
      "2021-01-11 12:51:16 - Trained model for 2 epochs with validation loss of 1.2796698212623596\n",
      "2021-01-11 12:51:20 - saving model at epoch 2 as the best model\n",
      "2021-01-11 12:51:20 - Training Epoch 3\n",
      "2021-01-11 12:51:27 - Invalid metric value: nan for channel train kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2021-01-11 12:51:27 - train total loss: 0.8698018463076772tempo loss: 0.13118925323983235, vel loss: 0.8674890870178068, dev loss: 0.7060655391699558, articul loss: 0.8604841183971714, pedal loss: 1.000370289022858, trill loss: 0.0, kld loss: nan, \n",
      "2021-01-11 12:51:27 - Invalid metric value: nan for channel valid kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2021-01-11 12:51:27 - valid total loss: 1.2676531275113423tempo loss: 4.871589144070943, vel loss: 1.2275665998458862, dev loss: 0.8465548058350881, articul loss: 0.9139960904916128, pedal loss: 0.8692110180854797, trill loss: 0.0, kld loss: nan, \n",
      "2021-01-11 12:51:27 - Trained model for 3 epochs with validation loss of 1.2676531275113423\n",
      "2021-01-11 12:51:35 - saving model at epoch 3 as the best model\n",
      "2021-01-11 12:51:35 - Training Epoch 4\n",
      "2021-01-11 12:51:42 - Invalid metric value: nan for channel train kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2021-01-11 12:51:42 - train total loss: 0.8436029545466105tempo loss: 0.13591560102033934, vel loss: 0.849357309738795, dev loss: 0.6809322369098664, articul loss: 0.8555623165766398, pedal loss: 0.9654092407226562, trill loss: 0.0, kld loss: nan, \n",
      "2021-01-11 12:51:42 - Invalid metric value: nan for channel valid kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2021-01-11 12:51:42 - valid total loss: 1.3089058796564739tempo loss: 5.315879027048747, vel loss: 1.2674692670504253, dev loss: 0.8484247525533041, articul loss: 0.9215499957402548, pedal loss: 0.8635201752185822, trill loss: 0.0, kld loss: nan, \n",
      "2021-01-11 12:51:42 - Trained model for 4 epochs with validation loss of 1.3089058796564739\n",
      "2021-01-11 12:51:45 - saving model at epoch 4 as the best model\n",
      "2021-01-11 12:51:45 - Training Epoch 5\n"
     ]
    }
   ],
   "source": [
    "run_training_experiment(\n",
    "    exp_name=exp_name,\n",
    "    exp_description=exp_description,\n",
    "    tags=tags,\n",
    "    is_dev=is_dev,\n",
    "    hyper_params=hyper_params,\n",
    "    job_params=job_params,\n",
    "    model_file_path=model_file_path,\n",
    "    model_class=model_class,\n",
    "    job_class=job_class\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "neptune": {
   "notebookId": "b58bd848-c507-40c0-9eb9-0fc1e4780d5b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
