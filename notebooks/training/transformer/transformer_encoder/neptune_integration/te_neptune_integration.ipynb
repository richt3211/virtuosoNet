{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.experiments.training.training import run_training_experiment\n",
    "from src.models.transformer import TransformerEncoder, TransformerEncoderHyperParams\n",
    "from src.experiments.training.Transformer.TransformerEncoder_training import TransformerEncoderJob, TransformerEncoderJobParams\n",
    "from src.models.model_run_job import ModelJob, ModelJobParams\n",
    "from src.constants import SRC_DIR\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"input_size\": 78,\n",
      "    \"output_size\": 11,\n",
      "    \"device_num\": 1,\n",
      "    \"time_steps\": 500,\n",
      "    \"is_dev\": false,\n",
      "    \"device\": \"cuda:1\",\n",
      "    \"num_head\": 6,\n",
      "    \"hidden_size\": 528,\n",
      "    \"num_layers\": 24,\n",
      "    \"dropout\": 0.1,\n",
      "    \"qpm_index\": 0,\n",
      "    \"vel_param_idx\": 1,\n",
      "    \"dev_param_idx\": 2,\n",
      "    \"articul_param_idx\": 3,\n",
      "    \"pedal_param_idx\": 4,\n",
      "    \"num_key_augmentation\": 1,\n",
      "    \"batch_size\": 1,\n",
      "    \"epochs\": 50,\n",
      "    \"num_tempo_param\": 1,\n",
      "    \"num_prime_param\": 11,\n",
      "    \"tempo_loss\": true,\n",
      "    \"learning_rate\": 3e-05,\n",
      "    \"grad_clip\": 0.5,\n",
      "    \"model_name\": \"TRANSFORMER ENCODER ONLY\"\n",
      "}\n",
      "https://ui.neptune.ai/richt3211/thesis/e/THESIS-125\n",
      "2020-12-07 19:21:55 - Starting experiment\n",
      "2020-12-07 19:21:56 - Reading Full Data\n",
      "2020-12-07 19:31:03 - STARTING None JOB AT 50 EPOCHS FOR  DATA SET\n",
      "2020-12-07 19:31:04 - Number of model params: 2591285\n",
      "2020-12-07 19:31:04 - TransformerEncoder(\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=528, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=528, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=528, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=528, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=528, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=528, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=528, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=528, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=528, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=528, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=528, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=528, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (6): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=528, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=528, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (7): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=528, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=528, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (8): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=528, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=528, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (9): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=528, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=528, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (10): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=528, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=528, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (11): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=528, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=528, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (12): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=528, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=528, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (13): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=528, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=528, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (14): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=528, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=528, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (15): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=528, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=528, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (16): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=528, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=528, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (17): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=528, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=528, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (18): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=528, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=528, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (19): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=528, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=528, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (20): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=528, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=528, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (21): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=528, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=528, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (22): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=528, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=528, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (23): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=528, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=528, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=78, out_features=11, bias=True)\n",
      ")\n",
      "2020-12-07 19:31:04 - Training Epoch 1\n",
      "2020-12-07 20:10:58 - Invalid metric value: nan for channel train kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2020-12-07 20:10:58 - train total loss: 1.1370402971056457tempo loss: 1.0272678953990562, vel loss: 1.0341919801275758, dev loss: 2.1715661264078627, articul loss: 1.0860703449231857, pedal loss: 1.0269066529933912, trill loss: 0.0, kld loss: nan, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uusoc/exports/scratch/rtimpson/thesis/virtuosoNet/env/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/uusoc/exports/scratch/rtimpson/thesis/virtuosoNet/env/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-07 20:11:29 - Invalid metric value: nan for channel valid kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2020-12-07 20:11:29 - valid total loss: 0.9953513661918997tempo loss: 1.3857407990856405, vel loss: 0.8644975229692297, dev loss: 0.7547148498373905, articul loss: 1.1543315714415239, pedal loss: 0.9699399952276223, trill loss: 0.0, kld loss: nan, \n",
      "2020-12-07 20:11:29 - Trained model for 1 epochs with validation loss of 0.9953513661918997\n",
      "2020-12-07 20:12:08 - saving model at epoch 1 as the best model\n",
      "2020-12-07 20:12:08 - Training Epoch 2\n",
      "2020-12-07 20:52:13 - Invalid metric value: nan for channel train kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2020-12-07 20:52:13 - train total loss: 1.1213793645721397tempo loss: 1.0388763740959002, vel loss: 1.0242902515910255, dev loss: 2.0459055988406782, articul loss: 1.0827273841894849, pedal loss: 1.020481865633187, trill loss: 0.0, kld loss: nan, \n",
      "2020-12-07 20:52:44 - Invalid metric value: nan for channel valid kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2020-12-07 20:52:44 - valid total loss: 0.9835377926500435tempo loss: 1.3503287647733837, vel loss: 0.8404172919244848, dev loss: 0.7607096092998344, articul loss: 1.1147580105015356, pedal loss: 0.9646716735301873, trill loss: 0.0, kld loss: nan, \n",
      "2020-12-07 20:52:44 - Trained model for 2 epochs with validation loss of 0.9835377926500435\n",
      "2020-12-07 20:53:20 - saving model at epoch 2 as the best model\n",
      "2020-12-07 20:53:20 - Training Epoch 3\n",
      "2020-12-07 21:33:46 - Invalid metric value: nan for channel train kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2020-12-07 21:33:46 - train total loss: 1.1165226442067273tempo loss: 0.9343181373921284, vel loss: 1.0165376187759065, dev loss: 2.1764414171942628, articul loss: 1.0758123093111822, pedal loss: 1.0112341834103622, trill loss: 0.0, kld loss: nan, \n",
      "2020-12-07 21:34:15 - Invalid metric value: nan for channel valid kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2020-12-07 21:34:15 - valid total loss: 0.9603573224724156tempo loss: 1.0012635560052834, vel loss: 0.8304334642901404, dev loss: 0.7856533788224325, articul loss: 1.077429904513163, pedal loss: 0.9813071417379869, trill loss: 0.0, kld loss: nan, \n",
      "2020-12-07 21:34:15 - Trained model for 3 epochs with validation loss of 0.9603573224724156\n",
      "2020-12-07 21:34:49 - saving model at epoch 3 as the best model\n",
      "2020-12-07 21:34:49 - Training Epoch 4\n"
     ]
    }
   ],
   "source": [
    "is_dev=False\n",
    "hyper_params = TransformerEncoderHyperParams(num_layers=24, hidden_size=528)\n",
    "job_params = TransformerEncoderJobParams(is_dev=is_dev, epochs=50)\n",
    "model_file_path = f\"{SRC_DIR}/models/transformer.py\"\n",
    "run_training_experiment(\n",
    "    exp_name=\"Doubling layer size again to see what happens\",\n",
    "    exp_description=\"doubling the layer size and hidden size again to see if an even bigger network will yield better results. \",\n",
    "    tags=['transformer_encoder'],\n",
    "    is_dev=is_dev,\n",
    "    hyper_params=hyper_params,\n",
    "    job_params=job_params,\n",
    "    model_file_path=model_file_path,\n",
    "    model_folder=\"transfomer/transformer_encoder\",\n",
    "    model_class=TransformerEncoder,\n",
    "    job_class=TransformerEncoderJob\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "neptune": {
   "notebookId": "b58bd848-c507-40c0-9eb9-0fc1e4780d5b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
