{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.experiments.training.training import run_training_experiment\n",
    "from src.models.transformer import TransformerEncoder, TransformerEncoderHyperParams\n",
    "from src.experiments.training.Transformer.TransformerEncoder_training import TransformerEncoderJob, TransformerEncoderJobParams\n",
    "from src.models.model_run_job import ModelJob, ModelJobParams\n",
    "from src.constants import SRC_DIR\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"input_size\": 78,\n",
      "    \"output_size\": 11,\n",
      "    \"device_num\": 1,\n",
      "    \"is_dev\": true,\n",
      "    \"num_head\": 6,\n",
      "    \"hidden_size\": 128,\n",
      "    \"num_layers\": 5,\n",
      "    \"dropout\": 0.1,\n",
      "    \"qpm_index\": 0,\n",
      "    \"vel_param_idx\": 0,\n",
      "    \"dev_param_idx\": 2,\n",
      "    \"articul_param_idx\": 3,\n",
      "    \"pedal_param_idx\": 4,\n",
      "    \"num_key_augmentation\": 1,\n",
      "    \"batch_size\": 1,\n",
      "    \"epochs\": 50,\n",
      "    \"num_tempo_param\": 1,\n",
      "    \"num_prime_param\": 11,\n",
      "    \"tempo_loss\": true,\n",
      "    \"learning_rate\": 3e-05,\n",
      "    \"grad_clip\": 0.5,\n",
      "    \"model_name\": \"TRANSFORMER ENCODER ONLY\"\n",
      "}\n",
      "https://ui.neptune.ai/richt3211/thesis/e/THESIS-90\n",
      "2020-11-30 16:26:19 - Starting experiment\n",
      "2020-11-30 16:26:20 - Reading Dev Data\n",
      "2020-11-30 16:26:24 - STARTING None JOB AT 50 EPOCHS FOR DEV DATA SET\n",
      "2020-11-30 16:26:24 - Number of model params: 226539\n",
      "2020-11-30 16:26:24 - TransformerEncoder(\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=128, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=128, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=128, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=128, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=128, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=78, out_features=11, bias=True)\n",
      ")\n",
      "2020-11-30 16:26:24 - Training Epoch 1\n",
      "2020-11-30 16:26:31 - Invalid metric value: nan for channel train kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2020-11-30 16:26:31 - train total loss: 0.9223439832256265tempo loss: 0.5098659629060023, vel loss: 0.6068859529005338, dev loss: 0.7824450261788826, articul loss: 0.8836270921850857, pedal loss: 1.051851358315716, trill loss: 0.0, kld loss: nan, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uusoc/exports/scratch/rtimpson/thesis/virtuosoNet/env/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/uusoc/exports/scratch/rtimpson/thesis/virtuosoNet/env/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-30 16:26:33 - Invalid metric value: nan for channel valid kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2020-11-30 16:26:33 - valid total loss: 1.2432495256265004tempo loss: 2.627828578154246, vel loss: 1.8889840841293335, dev loss: 0.779121237496535, articul loss: 1.453091561794281, pedal loss: 0.9895312190055847, trill loss: 0.0, kld loss: nan, \n",
      "2020-11-30 16:26:33 - Trained model for 1 epochs with validation loss of 1.2432495256265004\n",
      "2020-11-30 16:26:41 - saving model at epoch 1 as the best model\n",
      "2020-11-30 16:26:41 - Training Epoch 2\n",
      "2020-11-30 16:26:46 - Invalid metric value: nan for channel train kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2020-11-30 16:26:46 - train total loss: 0.8317961304971616tempo loss: 0.1253763526238209, vel loss: 0.4740440894479621, dev loss: 0.7160503994928648, articul loss: 0.8652505576610565, pedal loss: 0.9955765478415032, trill loss: 0.0, kld loss: nan, \n",
      "2020-11-30 16:26:46 - Invalid metric value: nan for channel valid kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2020-11-30 16:26:46 - valid total loss: 1.3251436750094097tempo loss: 3.370921770731608, vel loss: 2.243464708328247, dev loss: 0.7737628817558289, articul loss: 1.419233630100886, pedal loss: 0.9670281112194061, trill loss: 0.0, kld loss: nan, \n",
      "2020-11-30 16:26:46 - Trained model for 2 epochs with validation loss of 1.3251436750094097\n",
      "2020-11-30 16:26:49 - saving model at epoch 2 as the best model\n",
      "2020-11-30 16:26:49 - Training Epoch 3\n",
      "2020-11-30 16:26:54 - Invalid metric value: nan for channel train kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2020-11-30 16:26:54 - train total loss: 0.8186214402930377tempo loss: 0.1428403327248168, vel loss: 0.4633550027461901, dev loss: 0.7055638232459761, articul loss: 0.8491912610726814, pedal loss: 0.9776978754017451, trill loss: 0.0, kld loss: nan, \n",
      "2020-11-30 16:26:54 - Invalid metric value: nan for channel valid kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2020-11-30 16:26:54 - valid total loss: 1.3411102692286174tempo loss: 3.5737328926722207, vel loss: 2.344335595766703, dev loss: 0.7625687619050344, articul loss: 1.350789298613866, pedal loss: 0.9601123134295145, trill loss: 0.0, kld loss: nan, \n",
      "2020-11-30 16:26:54 - Trained model for 3 epochs with validation loss of 1.3411102692286174\n",
      "2020-11-30 16:26:57 - saving model at epoch 3 as the best model\n",
      "2020-11-30 16:26:57 - Training Epoch 4\n",
      "2020-11-30 16:27:02 - Invalid metric value: nan for channel train kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2020-11-30 16:27:02 - train total loss: 0.8038753580737423tempo loss: 0.09179667752572665, vel loss: 0.458278636653702, dev loss: 0.6890748905671107, articul loss: 0.8556736459979764, pedal loss: 0.9639721094787895, trill loss: 0.0, kld loss: nan, \n",
      "2020-11-30 16:27:02 - Invalid metric value: nan for channel valid kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2020-11-30 16:27:02 - valid total loss: 1.3438652753829956tempo loss: 3.684143304824829, vel loss: 2.403712352116903, dev loss: 0.7624676575263342, articul loss: 1.344868282477061, pedal loss: 0.9410465359687805, trill loss: 0.0, kld loss: nan, \n",
      "2020-11-30 16:27:02 - Trained model for 4 epochs with validation loss of 1.3438652753829956\n",
      "2020-11-30 16:27:07 - saving model at epoch 4 as the best model\n",
      "2020-11-30 16:27:07 - Training Epoch 5\n",
      "2020-11-30 16:27:11 - Invalid metric value: nan for channel train kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2020-11-30 16:27:11 - train total loss: 0.8113279399034139tempo loss: 0.10930165822422451, vel loss: 0.4673599906869837, dev loss: 0.6999322232362386, articul loss: 0.8343849886913557, pedal loss: 0.9733754597805642, trill loss: 0.0, kld loss: nan, \n",
      "2020-11-30 16:27:11 - Invalid metric value: nan for channel valid kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2020-11-30 16:27:11 - valid total loss: 1.3364600638548534tempo loss: 3.575771609942118, vel loss: 2.3579708536465964, dev loss: 0.7590693061550459, articul loss: 1.3434881766637166, pedal loss: 0.9521085421244303, trill loss: 0.0, kld loss: nan, \n",
      "2020-11-30 16:27:11 - Trained model for 5 epochs with validation loss of 1.3364600638548534\n",
      "2020-11-30 16:27:15 - saving model at epoch 5 as the best model\n",
      "2020-11-30 16:27:15 - Training Epoch 6\n"
     ]
    }
   ],
   "source": [
    "is_dev=True\n",
    "hyper_params = TransformerEncoderHyperParams()\n",
    "job_params = TransformerEncoderJobParams(is_dev=is_dev, epochs=50)\n",
    "model_file_path = f\"{SRC_DIR}/models/transformer.py\"\n",
    "run_training_experiment(\n",
    "    exp_name=\"With Tempo Loss\",\n",
    "    exp_description=\"Running with tempo loss instead of note loss\",\n",
    "    tags=['transformer_encoder'],\n",
    "    is_dev=is_dev,\n",
    "    hyper_params=hyper_params,\n",
    "    job_params=job_params,\n",
    "    model_file_path=model_file_path,\n",
    "    model_folder=\"transfomer/transformer_encoder\",\n",
    "    model_class=TransformerEncoder,\n",
    "    job_class=TransformerEncoderJob\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "neptune": {
   "notebookId": "b58bd848-c507-40c0-9eb9-0fc1e4780d5b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
