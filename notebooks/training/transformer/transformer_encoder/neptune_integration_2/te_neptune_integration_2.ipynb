{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.experiments.training.training import run_training_experiment\n",
    "from src.models.transformer import TransformerEncoder, TransformerEncoderHyperParams\n",
    "from src.experiments.training.Transformer.TransformerEncoder_training import TransformerEncoderJob, TransformerEncoderJobParams\n",
    "from src.models.model_run_job import ModelJob, ModelJobParams\n",
    "from src.constants import SRC_DIR\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = 1\n",
    "pedal = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerEncoderJobParams(input_size=78, output_size=11, device_num=1, time_steps=500, is_dev=False, device=device(type='cuda', index=1), qpm_index=0, vel_param_idx=1, dev_param_idx=2, articul_param_idx=3, pedal_param_idx=4, num_key_augmentation=1, batch_size=1, epochs=50, num_tempo_param=1, num_prime_param=11, criterion='torch', tempo_loss=True, articul_mask='pedal', tempo_weight=1, vel_weight=1, dev_weight=1, articul_weight=1, pedal_weight=7, learning_rate=3e-05, grad_clip=0.5, model_name='TRANSFORMER ENCODER ONLY')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "is_dev=False\n",
    "hyper_params = TransformerEncoderHyperParams(hidden_size=256, num_layers=12, num_head=13)\n",
    "job_params = TransformerEncoderJobParams(\n",
    "    is_dev=is_dev, \n",
    "    articul_mask=\"pedal\", \n",
    "    articul_weight = other,\n",
    "    dev_weight = other,\n",
    "    pedal_weight = pedal,\n",
    "    vel_weight = other,\n",
    "    tempo_weight=other, \n",
    "    epochs=50\n",
    ")\n",
    "model_file_path = f\"{SRC_DIR}/models/transformer.py\"\n",
    "exp_name=\"Increasing lr\"\n",
    "exp_description=\"Doing a more exhaustive parameter search\"\n",
    "model_folder=\"transformer/transformer_encoder\"\n",
    "model_class=TransformerEncoder\n",
    "job_class=TransformerEncoderJob\n",
    "tags=['transformer_encoder']\n",
    "display(job_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"input_size\": 78,\n",
      "    \"output_size\": 11,\n",
      "    \"device_num\": 1,\n",
      "    \"time_steps\": 500,\n",
      "    \"is_dev\": false,\n",
      "    \"device\": \"cuda:1\",\n",
      "    \"num_head\": 13,\n",
      "    \"hidden_size\": 256,\n",
      "    \"num_layers\": 12,\n",
      "    \"dropout\": 0.1,\n",
      "    \"qpm_index\": 0,\n",
      "    \"vel_param_idx\": 1,\n",
      "    \"dev_param_idx\": 2,\n",
      "    \"articul_param_idx\": 3,\n",
      "    \"pedal_param_idx\": 4,\n",
      "    \"num_key_augmentation\": 1,\n",
      "    \"batch_size\": 1,\n",
      "    \"epochs\": 50,\n",
      "    \"num_tempo_param\": 1,\n",
      "    \"num_prime_param\": 11,\n",
      "    \"criterion\": \"torch\",\n",
      "    \"tempo_loss\": true,\n",
      "    \"articul_mask\": \"pedal\",\n",
      "    \"tempo_weight\": 1,\n",
      "    \"vel_weight\": 1,\n",
      "    \"dev_weight\": 1,\n",
      "    \"articul_weight\": 1,\n",
      "    \"pedal_weight\": 7,\n",
      "    \"learning_rate\": 3e-05,\n",
      "    \"grad_clip\": 0.5,\n",
      "    \"model_name\": \"TRANSFORMER ENCODER ONLY\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There is a new version of neptune-client 0.4.130 (installed: 0.4.126).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ai/richt3211/thesis/e/THESIS-190\n",
      "2021-01-12 13:36:52 - Starting experiment\n",
      "2021-01-12 13:36:52 - Reading Full Data\n",
      "2021-01-12 13:48:13 - STARTING None JOB AT 50 EPOCHS FOR  DATA SET\n",
      "2021-01-12 13:48:14 - Number of model params: 783629\n",
      "2021-01-12 13:48:14 - TransformerEncoder(\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (6): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (7): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (8): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (9): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (10): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (11): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=78, out_features=11, bias=True)\n",
      ")\n",
      "2021-01-12 13:48:15 - Training Epoch 1\n",
      "2021-01-12 14:19:48 - Invalid metric value: nan for channel train kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2021-01-12 14:19:48 - train total loss: 1.0424995200093583tempo loss: 0.5897872709471593, vel loss: 0.8866492078597396, dev loss: 2.370226443663352, articul loss: 1.0623472207834197, pedal loss: 0.9369263132833778, trill loss: 0.0, kld loss: nan, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uusoc/exports/scratch/rtimpson/thesis/virtuosoNet/env/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/uusoc/exports/scratch/rtimpson/thesis/virtuosoNet/env/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-12 14:20:16 - Invalid metric value: nan for channel valid kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2021-01-12 14:20:16 - valid total loss: 0.8424960823153791tempo loss: 0.587135068623336, vel loss: 0.7968241259944665, dev loss: 0.7768303358505941, articul loss: 1.1737246095413576, pedal loss: 0.8475632153850351, trill loss: 0.0, kld loss: nan, \n",
      "2021-01-12 14:20:16 - Trained model for 1 epochs with validation loss of 0.8424960823153791\n",
      "2021-01-12 14:20:36 - saving model at epoch 1 as the best model\n",
      "2021-01-12 14:20:37 - Training Epoch 2\n",
      "2021-01-12 14:51:17 - Invalid metric value: nan for channel train kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2021-01-12 14:51:17 - train total loss: 0.9499385209624157tempo loss: 0.42517579923733106, vel loss: 0.7983144909721416, dev loss: 2.263030112512088, articul loss: 0.9642645824716081, pedal loss: 0.8569340582436505, trill loss: 0.0, kld loss: nan, \n",
      "2021-01-12 14:51:42 - Invalid metric value: nan for channel valid kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2021-01-12 14:51:42 - valid total loss: 0.8015385379768768tempo loss: 0.5196620593727534, vel loss: 0.7265631559322465, dev loss: 0.7602502761798469, articul loss: 1.0973564309689439, pedal loss: 0.8161559610820885, trill loss: 0.0, kld loss: nan, \n",
      "2021-01-12 14:51:42 - Trained model for 2 epochs with validation loss of 0.8015385379768768\n",
      "2021-01-12 14:51:57 - saving model at epoch 2 as the best model\n",
      "2021-01-12 14:51:57 - Training Epoch 3\n",
      "2021-01-12 15:23:20 - Invalid metric value: nan for channel train kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2021-01-12 15:23:20 - train total loss: 0.8620760161608191tempo loss: 0.370803369199004, vel loss: 0.751196011707223, dev loss: 1.6130350675430092, articul loss: 0.9060469759668014, pedal loss: 0.8345363602522612, trill loss: 0.0, kld loss: nan, \n",
      "2021-01-12 15:23:44 - Invalid metric value: nan for channel valid kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2021-01-12 15:23:44 - valid total loss: 0.8034844525158406tempo loss: 0.483562904920598, vel loss: 0.6781291107422319, dev loss: 0.7630591273468373, articul loss: 1.0253422869690534, pedal loss: 0.8411764695012043, trill loss: 0.0, kld loss: nan, \n",
      "2021-01-12 15:23:44 - Trained model for 3 epochs with validation loss of 0.8034844525158406\n",
      "2021-01-12 15:23:53 - saving model at epoch 3 as the best model\n",
      "2021-01-12 15:23:53 - Training Epoch 4\n",
      "2021-01-12 15:55:14 - Invalid metric value: nan for channel train kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2021-01-12 15:55:14 - train total loss: 0.9197103722705978tempo loss: 0.351637455099658, vel loss: 0.7253984255559154, dev loss: 2.4040938887104675, articul loss: 0.8691351396973753, pedal loss: 0.823792695422095, trill loss: 0.0, kld loss: nan, \n",
      "2021-01-12 15:55:40 - Invalid metric value: nan for channel valid kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2021-01-12 15:55:40 - valid total loss: 0.8007127137120538tempo loss: 0.45844102495089184, vel loss: 0.6687480721128992, dev loss: 0.7751693204542215, articul loss: 0.968105202646551, pedal loss: 0.848196568746575, trill loss: 0.0, kld loss: nan, \n",
      "2021-01-12 15:55:40 - Trained model for 4 epochs with validation loss of 0.8007127137120538\n",
      "2021-01-12 15:55:54 - saving model at epoch 4 as the best model\n",
      "2021-01-12 15:55:54 - Training Epoch 5\n",
      "2021-01-12 16:27:34 - Invalid metric value: nan for channel train kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2021-01-12 16:27:34 - train total loss: 0.8359740661223137tempo loss: 0.32414769789835146, vel loss: 0.7067466570867206, dev loss: 1.621287905589952, articul loss: 0.8457403675423242, pedal loss: 0.8139702626371369, trill loss: 0.0, kld loss: nan, \n",
      "2021-01-12 16:28:02 - Invalid metric value: nan for channel valid kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2021-01-12 16:28:02 - valid total loss: 0.7908809445153883tempo loss: 0.5070977498284558, vel loss: 0.6633753798463765, dev loss: 0.7587203286269157, articul loss: 0.9322234132040331, pedal loss: 0.834039038780329, trill loss: 0.0, kld loss: nan, \n",
      "2021-01-12 16:28:02 - Trained model for 5 epochs with validation loss of 0.7908809445153883\n",
      "2021-01-12 16:28:17 - saving model at epoch 5 as the best model\n",
      "2021-01-12 16:28:17 - Training Epoch 6\n",
      "2021-01-12 16:59:42 - Invalid metric value: nan for channel train kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2021-01-12 16:59:42 - train total loss: 0.8832536385110129tempo loss: 0.31369023780980876, vel loss: 0.694141854364279, dev loss: 2.2092725100299995, articul loss: 0.8239890678376008, pedal loss: 0.8106708681698269, trill loss: 0.0, kld loss: nan, \n",
      "2021-01-12 17:00:07 - Invalid metric value: nan for channel valid kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2021-01-12 17:00:07 - valid total loss: 0.7831718741766529tempo loss: 0.4992505423092486, vel loss: 0.6626527178163973, dev loss: 0.7566466508288457, articul loss: 0.8947843812496139, pedal loss: 0.8287937243940351, trill loss: 0.0, kld loss: nan, \n",
      "2021-01-12 17:00:07 - Trained model for 6 epochs with validation loss of 0.7831718741766529\n",
      "2021-01-12 17:00:22 - saving model at epoch 6 as the best model\n",
      "2021-01-12 17:00:22 - Training Epoch 7\n"
     ]
    }
   ],
   "source": [
    "run_training_experiment(\n",
    "    exp_name=exp_name,\n",
    "    exp_description=exp_description,\n",
    "    tags=tags,\n",
    "    is_dev=is_dev,\n",
    "    hyper_params=hyper_params,\n",
    "    job_params=job_params,\n",
    "    model_file_path=model_file_path,\n",
    "    model_class=model_class,\n",
    "    job_class=job_class\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run_path = f\"{SRC_DIR}/models/model_run_job.py\"\n",
    "upload_files = [model_file_path, model_run_path]\n",
    "exp = init_training_job(\n",
    "    is_dev=is_dev,\n",
    "    exp_name=exp_name,\n",
    "    exp_description=exp_description,\n",
    "    hyper_params=hyper_params,\n",
    "    job_params=job_params,\n",
    "    tags=tags,\n",
    "    upload_files=upload_files\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_dev:\n",
    "    data = get_dev_data(exp)\n",
    "else:\n",
    "    data = get_full_data(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_class(hyper_params)\n",
    "training_job = job_class(job_params, model, exp)\n",
    "training_job.run_job(data, model_folder=model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "neptune": {
   "notebookId": "27e0e111-95f9-4de2-8a10-6b454245dce9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
