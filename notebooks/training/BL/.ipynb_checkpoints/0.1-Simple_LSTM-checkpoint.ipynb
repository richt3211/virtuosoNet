{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src.init_logging'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-893a7b96543c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_featurized_cache\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_featurized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit_logger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src.init_logging'"
     ]
    }
   ],
   "source": [
    "from src.data.data_reader.read_featurized_cache import read_featurized\n",
    "from src.init_logging import init_logger\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training for very small dev data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/uusoc/exports/scratch/rtimpson/thesis/virtuosoNet/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'{DATA_DIR}/train/training_data_development.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the training data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f41cc431674b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdev_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_featurized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/scr/thesis/virtuosoNet/src/data/data_reader/read_featurized_cache.py\u001b[0m in \u001b[0;36mread_featurized\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# p = u.load()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# complete_xy = pickle.load(f)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mcomplete_xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtrain_xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplete_xy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/uusoc/exports/scratch/rtimpson/thesis/virtuosoNet/env/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1208\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1210\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1211\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/uusoc/exports/scratch/rtimpson/thesis/virtuosoNet/env/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36mload_binfloat\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_binfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBINFLOAT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_binfloat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/uusoc/exports/scratch/rtimpson/thesis/virtuosoNet/env/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dev_data = read_featurized(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.models.BL import LSTMBaseline\n",
    "from src.experiments.training.BL.LSTMSimple_training import train_model\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BL = LSTMBaseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for epoch 1/10\n",
      "\n",
      "Training Loss\n",
      "\tTotal Loss: 0.8444033861160278\n",
      "\ttempo loss: 0.3978 vel loss: 0.8531 dev loss: 0.7354 articul loss: 0.8108 pedal loss: 0.9381 \n",
      "Validation Loss and Evaluation\n",
      "\tTotal Loss: 1.0791216492652893\n",
      "\ttempo loss: 1.632 vel loss: 1.076 dev loss: 1.088 articul loss: 1.341 pedal loss: 0.9982 \n",
      "\n",
      "Training for epoch 2/10\n",
      "\n",
      "Training Loss\n",
      "\tTotal Loss: 0.8352405190467834\n",
      "\ttempo loss: 0.3379 vel loss: 0.8463 dev loss: 0.7364 articul loss: 0.8103 pedal loss: 0.9329 \n",
      "Validation Loss and Evaluation\n",
      "\tTotal Loss: 1.0968606372674305\n",
      "\ttempo loss: 1.895 vel loss: 1.076 dev loss: 1.089 articul loss: 1.349 pedal loss: 0.9881 \n",
      "\n",
      "Training for epoch 3/10\n",
      "\n",
      "Training Loss\n",
      "\tTotal Loss: 0.8309370160102845\n",
      "\ttempo loss: 0.3141 vel loss: 0.8388 dev loss: 0.7384 articul loss: 0.8108 pedal loss: 0.9301 \n",
      "Validation Loss and Evaluation\n",
      "\tTotal Loss: 1.1119480729103088\n",
      "\ttempo loss: 2.119 vel loss: 1.073 dev loss: 1.091 articul loss: 1.355 pedal loss: 0.9797 \n",
      "\n",
      "Training for epoch 4/10\n",
      "\n",
      "Training Loss\n",
      "\tTotal Loss: 0.8285832524299621\n",
      "\ttempo loss: 0.3019 vel loss: 0.8321 dev loss: 0.7397 articul loss: 0.8106 pedal loss: 0.9287 \n",
      "Validation Loss and Evaluation\n",
      "\tTotal Loss: 1.1237749854723613\n",
      "\ttempo loss: 2.295 vel loss: 1.071 dev loss: 1.092 articul loss: 1.36 pedal loss: 0.9731 \n",
      "\n",
      "Training for epoch 5/10\n",
      "\n",
      "Training Loss\n",
      "\tTotal Loss: 0.8268749260902405\n",
      "\ttempo loss: 0.2946 vel loss: 0.8272 dev loss: 0.7398 articul loss: 0.8086 pedal loss: 0.9278 \n",
      "Validation Loss and Evaluation\n",
      "\tTotal Loss: 1.132762328783671\n",
      "\ttempo loss: 2.428 vel loss: 1.069 dev loss: 1.092 articul loss: 1.362 pedal loss: 0.9684 \n",
      "\n",
      "Training for epoch 6/10\n",
      "\n",
      "Training Loss\n",
      "\tTotal Loss: 0.8252869327863057\n",
      "\ttempo loss: 0.2897 vel loss: 0.8238 dev loss: 0.7385 articul loss: 0.8043 pedal loss: 0.9268 \n",
      "Validation Loss and Evaluation\n",
      "\tTotal Loss: 1.1395279102855258\n",
      "\ttempo loss: 2.527 vel loss: 1.068 dev loss: 1.092 articul loss: 1.363 pedal loss: 0.9652 \n",
      "\n",
      "Training for epoch 7/10\n",
      "\n",
      "Training Loss\n",
      "\tTotal Loss: 0.823726212978363\n",
      "\ttempo loss: 0.2861 vel loss: 0.8215 dev loss: 0.7362 articul loss: 0.7985 pedal loss: 0.9258 \n",
      "Validation Loss and Evaluation\n",
      "\tTotal Loss: 1.1445924980299813\n",
      "\ttempo loss: 2.602 vel loss: 1.068 dev loss: 1.09 articul loss: 1.362 pedal loss: 0.9629 \n",
      "\n",
      "Training for epoch 8/10\n",
      "\n",
      "Training Loss\n",
      "\tTotal Loss: 0.8223267644643784\n",
      "\ttempo loss: 0.2835 vel loss: 0.8201 dev loss: 0.7341 articul loss: 0.7932 pedal loss: 0.9248 \n",
      "Validation Loss and Evaluation\n",
      "\tTotal Loss: 1.1484780857960384\n",
      "\ttempo loss: 2.659 vel loss: 1.068 dev loss: 1.089 articul loss: 1.36 pedal loss: 0.9612 \n",
      "\n",
      "Training for epoch 9/10\n",
      "\n",
      "Training Loss\n",
      "\tTotal Loss: 0.8212273703681098\n",
      "\ttempo loss: 0.2815 vel loss: 0.8189 dev loss: 0.7328 articul loss: 0.7896 pedal loss: 0.9239 \n",
      "Validation Loss and Evaluation\n",
      "\tTotal Loss: 1.1517220183655068\n",
      "\ttempo loss: 2.704 vel loss: 1.069 dev loss: 1.087 articul loss: 1.358 pedal loss: 0.9601 \n",
      "\n",
      "Training for epoch 10/10\n",
      "\n",
      "Training Loss\n",
      "\tTotal Loss: 0.8202169501781463\n",
      "\ttempo loss: 0.2798 vel loss: 0.8175 dev loss: 0.7317 articul loss: 0.7866 pedal loss: 0.9231 \n",
      "Validation Loss and Evaluation\n",
      "\tTotal Loss: 1.1546902736028035\n",
      "\ttempo loss: 2.74 vel loss: 1.07 dev loss: 1.087 articul loss: 1.358 pedal loss: 0.9596 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTMBaseline(\n",
       "  (lstm): LSTM(78, 11)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(dev_data, BL, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on full data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the training data\n",
      "number of train performances:  709 number of valid perf:  82\n",
      "training sample example [0.6979665018697635, -0.06717901528552674, -0.24900381647255815, -0.18282409397938054, -0.28513258251543067, -0.0476638292090852, -0.6054306213640016, -0.722166594420889, 0.16666666666666666, 0.0011402508551881414, 0, 0, 0, 0.25, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.3, 0, 0, 0, 0, -0.4, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.3, 0]\n"
     ]
    }
   ],
   "source": [
    "path = f'{DATA_DIR}/train/training_data.pickle'\n",
    "data = read_featurized(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.models.BL import LSTMBaseline\n",
    "from src.experiments.training.BL.LSTMSimple_training import train_model\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "BL = LSTMBaseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for epoch 1/10\n",
      "\n",
      "Training Loss\n",
      "\tTotal Loss: 1.2551979171624472\n",
      "\ttempo loss: 1.23 vel loss: 0.8101 dev loss: 0.9676 articul loss: 0.9119 pedal loss: 1.405 \n",
      "Validation Loss and Evaluation\n",
      "\tTotal Loss: 1.0470067349875845\n",
      "\ttempo loss: 2.493 vel loss: 0.7798 dev loss: 0.8187 articul loss: 1.149 pedal loss: 0.9438 \n",
      "\n",
      "Training for epoch 2/10\n",
      "\n",
      "Training Loss\n",
      "\tTotal Loss: 1.2728030589765151\n",
      "\ttempo loss: 1.367 vel loss: 0.8264 dev loss: 0.9805 articul loss: 0.9383 pedal loss: 1.407 \n",
      "Validation Loss and Evaluation\n",
      "\tTotal Loss: 1.0486307027863293\n",
      "\ttempo loss: 2.523 vel loss: 0.781 dev loss: 0.8194 articul loss: 1.15 pedal loss: 0.9417 \n",
      "\n",
      "Training for epoch 3/10\n",
      "\n",
      "Training Loss\n",
      "\tTotal Loss: 1.2769808940585925\n",
      "\ttempo loss: 1.418 vel loss: 0.8262 dev loss: 0.98 articul loss: 0.9376 pedal loss: 1.406 \n",
      "Validation Loss and Evaluation\n",
      "\tTotal Loss: 1.0428109159314536\n",
      "\ttempo loss: 2.534 vel loss: 0.7865 dev loss: 0.7934 articul loss: 1.098 pedal loss: 0.9377 \n",
      "\n",
      "Training for epoch 4/10\n",
      "\n",
      "Training Loss\n",
      "\tTotal Loss: 1.279378362315246\n",
      "\ttempo loss: 1.443 vel loss: 0.8303 dev loss: 0.9792 articul loss: 0.9362 pedal loss: 1.406 \n",
      "Validation Loss and Evaluation\n",
      "\tTotal Loss: 1.0397328555402232\n",
      "\ttempo loss: 2.539 vel loss: 0.7904 dev loss: 0.7826 articul loss: 1.077 pedal loss: 0.9346 \n",
      "\n",
      "Training for epoch 5/10\n",
      "\n",
      "Training Loss\n",
      "\tTotal Loss: 1.2801873631975043\n",
      "\ttempo loss: 1.458 vel loss: 0.8297 dev loss: 0.9783 articul loss: 0.9343 pedal loss: 1.405 \n",
      "Validation Loss and Evaluation\n",
      "\tTotal Loss: 1.037723307202502\n",
      "\ttempo loss: 2.542 vel loss: 0.7888 dev loss: 0.7795 articul loss: 1.071 pedal loss: 0.9321 \n",
      "\n",
      "Training for epoch 6/10\n",
      "\n",
      "Training Loss\n",
      "\tTotal Loss: 1.2799666310539255\n",
      "\ttempo loss: 1.469 vel loss: 0.828 dev loss: 0.9764 articul loss: 0.9307 pedal loss: 1.404 \n",
      "Validation Loss and Evaluation\n",
      "\tTotal Loss: 1.0357839859476903\n",
      "\ttempo loss: 2.544 vel loss: 0.7854 dev loss: 0.7748 articul loss: 1.061 pedal loss: 0.9306 \n",
      "\n",
      "Training for epoch 7/10\n",
      "\n",
      "Training Loss\n",
      "\tTotal Loss: 1.279619556880396\n",
      "\ttempo loss: 1.476 vel loss: 0.8278 dev loss: 0.9744 articul loss: 0.9267 pedal loss: 1.403 \n",
      "Validation Loss and Evaluation\n",
      "\tTotal Loss: 1.0344288165353317\n",
      "\ttempo loss: 2.545 vel loss: 0.7823 dev loss: 0.7708 articul loss: 1.053 pedal loss: 0.9299 \n",
      "\n",
      "Training for epoch 8/10\n",
      "\n",
      "Training Loss\n",
      "\tTotal Loss: 1.2793044630590464\n",
      "\ttempo loss: 1.482 vel loss: 0.8282 dev loss: 0.9728 articul loss: 0.9235 pedal loss: 1.402 \n",
      "Validation Loss and Evaluation\n",
      "\tTotal Loss: 1.0342884183202574\n",
      "\ttempo loss: 2.546 vel loss: 0.7797 dev loss: 0.7676 articul loss: 1.047 pedal loss: 0.9309 \n",
      "\n",
      "Training for epoch 9/10\n",
      "\n",
      "Training Loss\n",
      "\tTotal Loss: 1.279509043884098\n",
      "\ttempo loss: 1.486 vel loss: 0.8288 dev loss: 0.9715 articul loss: 0.921 pedal loss: 1.402 \n",
      "Validation Loss and Evaluation\n",
      "\tTotal Loss: 1.0343866613983785\n",
      "\ttempo loss: 2.547 vel loss: 0.7776 dev loss: 0.765 articul loss: 1.042 pedal loss: 0.9319 \n",
      "\n",
      "Training for epoch 10/10\n",
      "\n",
      "Training Loss\n",
      "\tTotal Loss: 1.279784057923029\n",
      "\ttempo loss: 1.489 vel loss: 0.8293 dev loss: 0.9706 articul loss: 0.919 pedal loss: 1.403 \n",
      "Validation Loss and Evaluation\n",
      "\tTotal Loss: 1.034628528465585\n",
      "\ttempo loss: 2.548 vel loss: 0.7758 dev loss: 0.7637 articul loss: 1.039 pedal loss: 0.9329 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTMBaseline(\n",
       "  (lstm): LSTM(78, 11)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(data, BL, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'valid'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
