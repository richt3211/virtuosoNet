{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598909070829",
   "display_name": "Python 3.7.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "from src.data.data_reader import load_development_training_data\n",
    "from src.models.BL import LSTM_Baseline, train_model\n",
    "import torch\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/uusoc/exports/scratch/rtimpson/chopin_cleaned\n../../../../chopin_cleaned/Mozart/Piano_Sonatas/8-1/\nNumber of non matched pairs: 0\nperformance name is Bogdanovitch01\nNumber of non matched pairs: 71\nNumber of mismatched notes:  60\ncheck trill pitch - detected pitch:  77  trill note pitch:  76 expected up trill pitch:  78 time: 73.38667875 measure:  42\nNumber of Matched Notes: 3140, unmatched notes: 107\nperformance name is LEE_J03\nNumber of non matched pairs: 52\nNumber of mismatched notes:  20\ncheck trill pitch - detected pitch:  77  trill note pitch:  76 expected up trill pitch:  78 time: 76.53304312499999 measure:  42\ncheck trill pitch - detected pitch:  77  trill note pitch:  76 expected up trill pitch:  78 time: 76.64735925 measure:  42\nNumber of Matched Notes: 3191, unmatched notes: 56\nperformance name is Lo01\nNumber of non matched pairs: 48\nNumber of mismatched notes:  68\ncheck trill pitch - detected pitch:  77  trill note pitch:  76 expected up trill pitch:  78 time: 80.7290859375 measure:  42\ncheck trill pitch - detected pitch:  77  trill note pitch:  76 expected up trill pitch:  78 time: 80.86129734375001 measure:  42\nNumber of Matched Notes: 3159, unmatched notes: 88\nperformance name is Rozanski02\nNumber of non matched pairs: 24\nNumber of mismatched notes:  77\ncheck trill pitch - detected pitch:  77  trill note pitch:  76 expected up trill pitch:  78 time: 81.76407421875001 measure:  42\nNumber of Matched Notes: 3173, unmatched notes: 74\nperformance name is Jia01\nNumber of non matched pairs: 46\nNumber of mismatched notes:  60\ncheck trill pitch - detected pitch:  77  trill note pitch:  76 expected up trill pitch:  78 time: 75.475351875 measure:  42\ncheck trill pitch - detected pitch:  77  trill note pitch:  76 expected up trill pitch:  78 time: 75.8252446875 measure:  42\nNumber of Matched Notes: 3157, unmatched notes: 90\n../../../../chopin_cleaned/Bach/Fugue/bwv_874/\nNumber of non matched pairs: 0\nperformance name is Kurz01\nNumber of non matched pairs: 7\nNumber of mismatched notes:  0\nNumber of Matched Notes: 868, unmatched notes: 7\nperformance name is WongWY01\nNumber of non matched pairs: 3\nNumber of mismatched notes:  0\nNumber of Matched Notes: 872, unmatched notes: 3\nperformance name is BianF01\nNumber of non matched pairs: 2\nNumber of mismatched notes:  0\nNumber of Matched Notes: 873, unmatched notes: 2\n../../../../chopin_cleaned/Liszt/Transcendental_Etudes/5/\nNumber of non matched pairs: 2\nperformance name is Huangci01\nNumber of non matched pairs: 309\nNumber of mismatched notes:  74\nNumber of Matched Notes: 4165, unmatched notes: 380\nperformance name is Min03\nNumber of non matched pairs: 344\nNumber of mismatched notes:  28\nNumber of Matched Notes: 4174, unmatched notes: 371\nperformance name is LiuY06\nNumber of non matched pairs: 273\nNumber of mismatched notes:  36\nNumber of Matched Notes: 4239, unmatched notes: 306\nperformance name is Gryaznov02\nNumber of non matched pairs: 227\nNumber of mismatched notes:  35\nNumber of Matched Notes: 4283, unmatched notes: 262\nperformance name is Huang16\nNumber of non matched pairs: 313\nNumber of mismatched notes:  38\nNumber of Matched Notes: 4197, unmatched notes: 348\nperformance name is Wang06\nNumber of non matched pairs: 202\nNumber of mismatched notes:  42\nNumber of Matched Notes: 4303, unmatched notes: 242\nperformance name is Sun09\nNumber of non matched pairs: 164\nNumber of mismatched notes:  17\nNumber of Matched Notes: 4367, unmatched notes: 178\nperformance name is Park03\nNumber of non matched pairs: 389\nNumber of mismatched notes:  30\nNumber of Matched Notes: 4128, unmatched notes: 417\nperformance name is WangY02\nNumber of non matched pairs: 622\nNumber of mismatched notes:  56\nNumber of Matched Notes: 3873, unmatched notes: 672\nperformance name is KIM_W02\nNumber of non matched pairs: 195\nNumber of mismatched notes:  17\nNumber of Matched Notes: 4333, unmatched notes: 212\nperformance name is HUAN_B03\nNumber of non matched pairs: 359\nNumber of mismatched notes:  126\nNumber of Matched Notes: 4081, unmatched notes: 464\nNumber of train pairs:  5 valid pairs:  3 test pairs:  11\nTotal data point is  0\nNumber of total piece is  3  and total performance is  19\nNumber of training perform is  5  number of valid perform is 3  and test performance is  11\n68855\n[65, 0.125, 1, 2.0, 1.952611921727238, 0.0, 0.0, 0.5, 0.25, 0.001890359168241966, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0.3, 0, 0, 0, 0, -0.4, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.3, 0]\n[1.9338497850921805, 41, 0.0, -0.15661290565983105, 0, 0, 0, 0, 5, 0, 0, 1.9338497850921805, 44.5, 1.9622032810860177, 54.583333333333336, 0, 0, 0, 0, 0]\n[[69.87897756154237, 0.2909901241739889, 1.060416817950766, 2.5435044659066155, 1.992364748267935, 0.03240505409919396, 29.18734478251398, 108.7290483625009], [1.9290315296568104, 64.29832256190545, 0.0027532427873908525, -0.3406356580560922, 0.021720763189537317, 0.3555575204939937, 55.198024834797764, 57.98585433156634, 43.044964054897974, 53.29961513325104, 51.49948442378912, 1.9290315296568104, 64.21614715602416, 1.9261210172182706, 64.21957289013237, 8.347552673689338, 0.9111950877841588, 0.6484417343967995, 1.9429048097335868], []]\n[[12.72194638535415, 0.3217724703384345, 1.2937439388772685, 0.8965674330699468, 0.07682444143077449, 0.23477269657081692, 32.58442475236884, 133.0421492877668], [0.13239642826039225, 15.24699039444318, 0.052211738726989435, 0.3119557363505264, 0.10065337180314972, 5.360688090781936, 51.85975694230675, 52.48603456443594, 56.61053852660265, 51.62806818145837, 51.13178545124165, 0.13239642826039225, 10.570797086779772, 0.12757316082356918, 9.915632390023074, 2.2684933667332126, 0.155894889204628, 0.3192903672338196, 0.854967130923716], []]\n"
    }
   ],
   "source": [
    "features = load_development_training_data(\"../../../../chopin_cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_Baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loss is: 0.5881077647209167\nLoss is: 0.5809265375137329\nLoss is: 0.6644856929779053\nLoss is: 0.6079291701316833\nLoss is: 0.5646082162857056\nLoss is: 0.5889402627944946\nLoss is: 0.5821717381477356\nLoss is: 0.6643182039260864\nLoss is: 0.6079606413841248\nLoss is: 0.5637884140014648\nLoss is: 0.5894641876220703\nLoss is: 0.5826495885848999\nLoss is: 0.6644309163093567\nLoss is: 0.6081326007843018\nLoss is: 0.5616852641105652\nLoss is: 0.5897467136383057\nLoss is: 0.5823598504066467\nLoss is: 0.664932131767273\nLoss is: 0.6085407733917236\nLoss is: 0.5579759478569031\nLoss is: 0.5899599194526672\nLoss is: 0.5813748240470886\nLoss is: 0.6661138534545898\nLoss is: 0.6094396710395813\nLoss is: 0.5525203347206116\nLoss is: 0.5904217958450317\nLoss is: 0.5799349546432495\nLoss is: 0.668412983417511\nLoss is: 0.6111716628074646\nLoss is: 0.5456939339637756\nLoss is: 0.5915012359619141\nLoss is: 0.5784434080123901\nLoss is: 0.672023594379425\nLoss is: 0.6138445138931274\nLoss is: 0.5385921001434326\nLoss is: 0.5931591987609863\nLoss is: 0.5771088600158691\nLoss is: 0.6763590574264526\nLoss is: 0.6168251037597656\nLoss is: 0.5323875546455383\nLoss is: 0.5945726037025452\nLoss is: 0.5756309628486633\nLoss is: 0.6802305579185486\nLoss is: 0.6190018653869629\nLoss is: 0.5277607440948486\nLoss is: 0.5947162508964539\nLoss is: 0.57358717918396\nLoss is: 0.6827660202980042\nLoss is: 0.6196860074996948\nLoss is: 0.5252370834350586\nValidation Loss is: 0.5247846841812134\nValidation Loss is: 0.5247846841812134\nValidation Loss is: 0.5247846841812134\nValidation Loss is: 0.5247846841812134\nValidation Loss is: 0.5247846841812134\nValidation Loss is: 0.5247846841812134\nValidation Loss is: 0.5247846841812134\nValidation Loss is: 0.5247846841812134\nValidation Loss is: 0.5247846841812134\nValidation Loss is: 0.5247846841812134\nValidation Loss is: 0.5247846841812134\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LSTM_Baseline(\n  (lstm): LSTM(78, 20)\n)"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "train_model(features, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of now there is quite a bit of work I need to do to get the model working. I do need to reproduce the basline LSTM model as well as the full end to end data pipeline for managing the data input and output. To do this I think the best way to accomplish it is in going to be picking from the old code into a completely refactored system which I am currently doing. As I gain better understanding of the networks and PyTorch, this should be easier. \n",
    "\n",
    "I think one of the things I am lacking most right now is a proper understanding of the data. All of the data pre-processing is a LOT more complicated than I thought it would be. He does provide the pyScoreParser package which does all of the heavy lifting, but understanding what it is doing to the data is not trivial. It may be useful for me to actually go back through and copy some of the data processing code so that I can understand what goes behind it. This won't necessarily be a waste, as I might attempt to do some feature engineering myself. \n",
    "\n",
    "I need to keep hacking away at the project. His code is extremely difficult to understand, so I think it is going to take quite a bit of time to get the understanding of the current system that I need. Rather than modify his code the best thing for me to do is simply re build his models from scratch. This should be a good goal for me. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tensor([[[ 7.2183e-01,  1.4178e-01, -2.5951e-01,  ...,  7.0726e-02,\n           2.7173e-02,  5.8324e-04]],\n\n        [[ 9.5044e-01,  1.5904e-01, -1.8915e-01,  ...,  8.6156e-02,\n           3.9973e-02,  3.4718e-02]],\n\n        [[ 9.9196e-01,  1.3979e-01, -2.5593e-01,  ...,  5.6907e-02,\n           4.2682e-02,  4.4922e-02]],\n\n        ...,\n\n        [[ 1.0000e+00,  3.8443e-02, -1.7616e-01,  ...,  1.4326e-02,\n           3.2262e-04, -5.7349e-04]],\n\n        [[ 1.0000e+00,  2.8174e-02, -2.0736e-01,  ...,  8.3847e-03,\n           2.2083e-04, -1.8570e-03]],\n\n        [[ 1.0000e+00,  4.8050e-02, -2.0556e-01,  ...,  1.4043e-02,\n           6.2603e-04, -2.8574e-03]]])"
     },
     "metadata": {}
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    test = features['test'][0][0]\n",
    "    # display(test)\n",
    "\n",
    "    test = torch.tensor(test, dtype=torch.float)\n",
    "    output = model(test)\n",
    "    display(output)\n",
    "\n",
    "\n",
    "# for xy_tuple in data['valid']:\n",
    "    # x = xy_tuple[0]\n",
    "    # y = xy_tuple[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}