{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation.quantitative import TransformerEncoderQuantitativeEvaluator\n",
    "from src.neptune import init_evaluation\n",
    "from src.data.data_reader.read_featurized_cache import read_featurized_test\n",
    "from src.constants import CACHE_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading test data in notebook so that I can run evaluation for many jobs quickly\n",
    "file_path = f'{CACHE_DATA_DIR}/train/training_data_test.pickle'\n",
    "test_data = read_featurized_test(file_path, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There is a new version of neptune-client 0.4.130 (installed: 0.4.126).\n",
      "WARNING: There is a new version of neptune-client 0.4.130 (installed: 0.4.126).\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_best.pth'\n",
    "params = 'params.pickle'\n",
    "train_params = 'train_params.pickle'\n",
    "artifacts = [model_name, params, train_params]\n",
    "exp = init_evaluation('THESIS-195', artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-15 09:51:07 - Running test set evaluation\n",
      "2021-01-15 09:51:07 - Reading in model\n",
      "2021-01-15 09:51:07 - Reading in test data\n",
      "2021-01-15 09:51:07 - Running evaluation\n",
      "TransformerEncoder(\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=78, out_features=78, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=78, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=78, bias=True)\n",
      "        (norm1): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((78,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): Linear(in_features=78, out_features=11, bias=True)\n",
      ")\n",
      "2021-01-15 09:51:22 - Invalid metric value: nan for channel test kld loss. Metrics with nan or +/-inf values will not be sent to server\n",
      "2021-01-15 09:51:22 - test total loss: 0.8646028989406173tempo loss: 0.4631166458653431, vel loss: 0.7777364497874365, dev loss: 0.8830449586723347, articul loss: 0.8483764708345366, pedal loss: 0.9340510152843456, trill loss: 0.0, kld loss: nan, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uusoc/exports/scratch/rtimpson/thesis/virtuosoNet/env/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/uusoc/exports/scratch/rtimpson/thesis/virtuosoNet/env/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "model_path = f'artifacts/{model_name}'\n",
    "quantitative_evaluator = TransformerEncoderQuantitativeEvaluator(exp=exp, is_dynamic_source=False)\n",
    "quantitative_evaluator.run_quantitative_evaluation_on_test_set(model_path, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
