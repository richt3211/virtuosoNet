{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599149155465",
   "display_name": "Python 3.7.8 64-bit ('env')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "After discussion with my advisor, I wanted to come in and redesign the infrastructure for the system at a high level. Many of the systems already exist to handle all of the different parts of the system, but they are done in a fragmented way without much thought put into the engineering. I'd like to approach this by doing the following. \n",
    "\n",
    "1. Describe a general framework for Data Science and Machine learning projects and the different components that need to exist to successfully run experiments\n",
    "2. Outline how the current project handles those different components\n",
    "3. Propose at a high level how a newly engineered archictecture can handle those components in a modular, reliable, and sustainable way. \n",
    "\n",
    "## 1. Components of a Machine Learning project\n",
    "Although every ML project is going to drastically differ in it's problem and the implementation of it's related solution, there are several components that will stay the same across most ML projects. These components can broadly be broken into 3 categories. \n",
    "\n",
    "1. Data\n",
    "2. Models\n",
    "3. Evaluation\n",
    "\n",
    "The data includes all of the code and infrastructure that is involved in gathering, storing, processing the data that is used to interface the model both for training and evaluation purposes. The models will train using the data to learn the target function they are trying to represent, and in some cases will actually be used in real life situations to output predictions for a commercial or business use case. As is often the case, there may be several models that are developed and used to find the best way to represent the target function given the data that exists. The model selection and development is going to depend on the evaluation of the models once they have been trained. Evaluation is as simple as testing the model on data that has never been seen before to get a sense of how well it has learned. In our case, the evaluation can either be quantitative or qualitative – the former relying on statistical metrics that are specific to the data representation of the problem, while the latter may rely on more subjective measures that involve realy human feedback, such as a listening test. \n",
    "\n",
    "Because each of these components remains mostly consistent across different projects, we will define a process that outlines the full end-2-end flow of developing and using ML models. The flow looks something like this \n",
    "\n",
    "![Machine Learning Components](ML-Components.png)\n",
    "\n",
    "Each of the boxes represents a different category of work, and the different colored lines represent the different flows that the system will use with the different components. The boxes will correspond with a code module to perform tasks such, whereas the flows will correspond with \"experiments\" or scripts that use the code modules to run the experiments. The different code modules are roughly defined below, with further expansion later on. \n",
    "\n",
    "### 1.1 Code Modules\n",
    "\n",
    "* Data \n",
    "    * Input Raw Data Reader \n",
    "    * Input Raw Data Pre-Processing to Model Input Features (Intermediate Data Form)\n",
    "    * Input Feature Cache Data Writer\n",
    "    * Input Feature Cache Data Reader \n",
    "    * Output Feature Post-Processing to Raw Data\n",
    "    * Output Raw Data Writer \n",
    "    * Output Raw Data Reader\n",
    "* Models \n",
    "    * Model Definition \n",
    "        * NN Architecture\n",
    "        * Forward Pass\n",
    "        * Loss function \n",
    "    * Model Training Loop \n",
    "    * Trained model writer \n",
    "    * Trained model reader \n",
    "    * Model Inference\n",
    "* Evaluation \n",
    "    * Quantitative Evaluator \n",
    "        * Uses Model Output and Training Output\n",
    "    * Qualitative Evaluator \n",
    "        * Uses Raw Data Output and presents it to Humans for feedback\n",
    "    * Metric Writer \n",
    "    * Metric Reader \n",
    "    * Interpretation \n",
    "        * Graphs\n",
    "        * Tables \n",
    "        * Visualizations\n",
    "\n",
    "Note: There is no definition in the evaluation model for a production system. This is because the \"production\" system won't necessarily exist in code, although it is possible. For now, this will simply mean taking a MIDI file and sending it to a piano synthesizer. This will be used for the qualitative listening tests, which also will not exist in code.\n",
    "\n",
    "### 1.2 Code Experiments \n",
    "* Initial Data Processing \n",
    "    * Reads in raw data (both input and output), converts it to featurized form, and stores in cache \n",
    "        * Module: Data\n",
    "* Training Loop \n",
    "    * Reads in featurized training input and output \n",
    "        * Module: Data\n",
    "    * Instantiaties new Model \n",
    "        * Module: Model\n",
    "    * Loop for x number of Epochs \n",
    "        * Create batches \n",
    "            * Module: Data\n",
    "        * Make a forward pass \n",
    "            * Module: Model\n",
    "        * Calculate the Loss\n",
    "            * Module: Model \n",
    "        * Backpropagate Loss Module: Model\n",
    "        * Calculate validation loss \n",
    "            * Module: Model\n",
    "        * Print training and validation loss \n",
    "    * Save trained model \n",
    "        * Module: Data\n",
    "* Test Inference and Quantitave Evaluation \n",
    "    * Read in featurized test input, output, and saved model \n",
    "        * Module: Data, Model\n",
    "    * Run test input through model \n",
    "        * Module: Model\n",
    "    * Calculate and write quantitative evaluation metrics with model output and test output \n",
    "        * Module: Evaluation\n",
    "    * Post-Process model output to raw output data and write to cache \n",
    "        * Module: Data\n",
    "* Production Interence\n",
    "    * Read production input and trained model\n",
    "        * Module: Data, Model \n",
    "    * Get model output from data \n",
    "        * Module: Model\n",
    "    * Post-Process output to raw output data \n",
    "        * Module: Data \n",
    "    * Write raw data\n",
    "        * Module: Data\n",
    "* Qualitative Evaluation\n",
    "    * Read in raw model output \n",
    "    * Send raw data to production system, gather human feedback\n",
    "    * Calculate Metrics \n",
    "    * Write Metrics \n",
    "\n",
    "## 2. Current implementations in the existing system \n",
    "Because I am working from an already existing system, all of components of the system exist. However, they don't exist in a maintable way. To put it bluntly, it's all spaghetti code. However, I have read through much of the existing code and have a somewhat decent understanding of where each of the different components exist. I won't go into details about every different code module component and where it specifically lives in the existing system, mostly because I don't know the specifics for every different part. However, I do have a broad understanding of where the different components live at a high level. \n",
    "\n",
    "Most of, if not all of, the Data code lives inside of the pyScoreParser package. This package is responsible for reading in training input MusicXML and training output MIDI, featurizing it for training, and doing this process in reverse; taking featurized model output and converting that data to MIDI. It contains code that also performs an alignment between the training MusicXML and MIDI to ensure that all of the notes are aligned with each other for the training process. \n",
    "\n",
    "All of the model definitions exist in a file named nnModel.py. I also believe that some of the training loop code also exists inside of the nnModel package as well. \n",
    "\n",
    "The model_run.py file contains both the Training Loop, and all Evaluation code. You can configure the script to run a training job, generate MIDI output (which would then be used for qualitative evalution), and also perform a quantitative evaluation \n",
    "\n",
    "## 3. API Proposal \n",
    "Given all of the previous information, we'll present an API that will follow the architecture diagram and make use of the existing system code. The API will be presented as Python function and class definitions. We'll also present the folder structure for the project to help structure the data, models, Python Modules, and Scripts, as well as talk a little bit about the development process and how it relates to the repository \n",
    "\n",
    "#### 3.1 Jupyter Notebooks \n",
    "I typically do all of my development in Jupyter Notebooks because of the interactive benefits they provide. One example is the development of model training. It is nice to only have to load the training data into memory one time and then make updates to the training code instead of reloading the training data and running the entire script every time a change is made. However, Jupyter Notebooks can lead to very messy and unmaintainable code. The general strategy that I'll employ is to move the code I write in Jupyter Notebook's to Python module's and packages often, and always keep the notebooks lightweight and simple. The notebooks will ultimately be the source for running the data, training, and evaluation scripts. This can happen either through the Jupyter Notebook UI, or by converting the Notebook to a script using %nbconvert. The latter strategy is useful for running longer training jobs. \n",
    "\n",
    "### 3.2 Folder Structure \n",
    "The folder structure will roughly look like this \n",
    "\n",
    "```plain\n",
    ".\n",
    "├── virtuosoData\n",
    "│   ├── input\n",
    "│   │   ├── development\n",
    "│   │   └── production\n",
    "│   └── output\n",
    "└── virtuosoNet\n",
    "    ├── data\n",
    "    │   ├── test\n",
    "    │   └── train\n",
    "    ├── models\n",
    "    ├── notebooks\n",
    "    │   ├── data_processing\n",
    "    │   ├── inference\n",
    "    │   │   ├── production\n",
    "    │   │   └── test\n",
    "    │   └── training\n",
    "    ├── pyScoreParser\n",
    "    └── src\n",
    "        ├── data\n",
    "        ├── evaluation\n",
    "        ├── experiments\n",
    "        │   ├── data_processing\n",
    "        │   ├── inference\n",
    "        │   │   ├── production\n",
    "        │   │   └── test\n",
    "        │   └── training\n",
    "        └── models\n",
    "```\n",
    "\n",
    "Both virtuosoData and virtuosoNet will be separate repositories, as this follows the sturcture of the original project. pyScoreParser is left it it's own folder, as it is also a seperate repository and will be a submodule underneath virtuosoNet. \n",
    "\n",
    "virtuosoData will contain the raw MusicXML and MIDI data and is separated by input and output data. The input data holds both MusicXML and MIDI data, and is used for the input to the model. The output will contain the raw MIDI file that comes as a result of an a model output. This will be used for the qualitative evaluation. The input data is split into development and production data. The development data can be split into whatever train/validation/test split is necessary for training and quantitative. The production folder will contain data that is to be used for inference with the end goal of passing raw output data to a production system, which will be used for qualitative evaluation. It's important to note that only the raw data exists in this repository, as the intermediate cached form will live inside of virtuosoNet. \n",
    "\n",
    "virtuosoNet will follow a simple folder structure that models the architecture diagram. The data folder will hold the cached version of both the development and production data sets. The models folder will hold any pre-trained models, and should ideally be organized by different models and different versions. The notebooks folder will hold all of the development notebooks, which should also be named with versions to keep organization clear. The subfolders inside of notebooks correspond with the different flows through the system. As was mentioned before, notebooks should be lightweight and simple, with most of the heavy lifting done in Python packages. The src folder is going to hold all such packages. The data, evaluation, and models folder corresponds to the different ML components defined in the architecture diagram. The experiments subfolders correspond with the notebooks subfolders, indicating that the experiment type run inside of notebooks should use the module code from src/experiments. As a concrete example, any notebook under notebooks/data_processing will make heavy use of the python packages defined inside of src/experiments/data_processings. \n",
    "\n",
    "## 3.2 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Score:\n",
    "    def __init__():\n",
    "        pass\n",
    "\n",
    "class Performance:\n",
    "    def __init__():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "src/data/data_reader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/data/data_reader.py\n",
    "\n",
    "# Input Raw Data Reader \n",
    "#     * Input Raw Data Pre-Processing to Model Input Features (Intermediate Data Form)\n",
    "#     * Input Feature Cache Data Writer\n",
    "#     * Input Feature Cache Data Reader \n",
    "#     * Output Feature Post-Processing to Raw Data\n",
    "#     * Output Raw Data Writer \n",
    "#     * Output Raw Data Reader\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "\n",
    "\n",
    "def read_raw_development_data(path: str, split: dict) -> Dict[str, List[Tuple(Score, Performance)]]:\n",
    "    '''Takes in the path to the raw training data and an optional split dictionary which defines \n",
    "    the specific subfolders which are to be used for the different splits \n",
    "    \n",
    "    This method will read all of the MusicXml and MIDI files defined in the split, and create a Score \n",
    "    and related Performance object that contains the note-aligned object features for every performance.\n",
    "\n",
    "    It will return a dictionary keyed by split type that holds a List of Tuples containing each Score and \n",
    "    Performance object. \n",
    "    '''\n",
    "    pass\n",
    "\n",
    "def read_raw_input_production_data(path: str) -> List[Score]:\n",
    "    '''Takes in the path to the raw production data\n",
    "\n",
    "    Reads all of the musicxml files and parses each file into a Score object. \n",
    "\n",
    "    Returns a list of all Score objects\n",
    "    '''\n",
    "\n",
    "def read_cached_development_data(file_path: str) -> List[Tuple[List[T], List[T]]]:\n",
    "    '''Reads in the cached object that was stored after pre-processing\n",
    "    \n",
    "    If file doesn't exists, throws error. \n",
    "\n",
    "    If the read object doesn't match the format for the cached data, throws error\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "src/data/data_writer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/data/data_writer.py\n",
    "\n",
    "# Input Raw Data Reader \n",
    "#     * Input Raw Data Pre-Processing to Model Input Features (Intermediate Data Form)\n",
    "#     * Input Feature Cache Data Writer\n",
    "#     * Input Feature Cache Data Reader \n",
    "#     * Output Feature Post-Processing to Raw Data\n",
    "#     * Output Raw Data Writer \n",
    "#     * Output Raw Data Reader\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def write_cached_development_data(file_path: str, data: None, split_type: str) -> None:\n",
    "    '''Writes the pre-processed data object to the specified path\n",
    "    \n",
    "    The data object should be a list of a two tuple of lists, containting the \n",
    "    score and performance features in vector form. Each data object should only contain \n",
    "    the performances for a single split, and the file_path should contain an organization \n",
    "    such that file and folder name make sense for each split.\n",
    "    '''\n",
    "\n",
    "def write_raw_production_midi(file_path:str, midi) -> None:\n",
    "    '''Writes the specified midi object to a midi file at the specified path'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "src/data/pre_processer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/data/pre_processor.py\n",
    "\n",
    "# Input Raw Data Reader \n",
    "#     * Input Raw Data Pre-Processing to Model Input Features (Intermediate Data Form)\n",
    "#     * Input Feature Cache Data Writer\n",
    "#     * Input Feature Cache Data Reader \n",
    "#     * Output Feature Post-Processing to Raw Data\n",
    "#     * Output Raw Data Writer \n",
    "#     * Output Raw Data Reader\n",
    "from typing import Tuple, List, TypeVar \n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "def featurize_score_and_performances(data: List[Tuple[Score, Performance]]) -> List[Tuple[List[T], List[T]]]:\n",
    "    '''Takes in a list of data performances and transforms the Score and Performance objects to featurized vectors'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "src/data/post_processor.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/data/pre_processor.py\n",
    "\n",
    "# Input Raw Data Reader \n",
    "#     * Input Raw Data Pre-Processing to Model Input Features (Intermediate Data Form)\n",
    "#     * Input Feature Cache Data Writer\n",
    "#     * Input Feature Cache Data Reader \n",
    "#     * Output Feature Post-Processing to Raw Data\n",
    "#     * Output Raw Data Writer \n",
    "#     * Output Raw Data Reader\n",
    "from typing import Tuple, List, TypeVar \n",
    "from pretty_midi import PrettyMIDI\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "def defeaturize_output_to_midi(data: List[Sequence[T]]) -> List[PrettyMIDI]:\n",
    "    '''Takes a list of outputs from the model and converts model outputs to MIDI objects\n",
    "    \n",
    "    Returns the list of performances as PrettyMIDI objects\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Models\n",
    "There are going to be several different models that are developed and maintained. For the purposes of this project, I am going to define a base model experiment class that will define a NN model but also expose functions for training, model reading and writing, and model inference. Every new model should make use of this class. Each file inside of the models folder should contain a pyTorch class model definition and also a ModelExperiment class definition. The ModelExperiment class will be used in the training script "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "src/models/model_experiment.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Model Definition \n",
    "#     * NN Architecture\n",
    "#     * Forward Pass\n",
    "#     * Loss function \n",
    "# * Model Training Loop \n",
    "# * Trained model writer \n",
    "# * Trained model reader \n",
    "# * Model Inference\n",
    "\n",
    "\n",
    "\n",
    "class ModelExperiment:\n",
    "    def __init__(self, nn_model):\n",
    "        self.nn_model = nn_model\n",
    "\n",
    "    def train_model(self):\n",
    "        pass\n",
    "    def write_model(self):\n",
    "        pass\n",
    "    def read_model(self):\n",
    "        pass\n",
    "    def model_inference(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}